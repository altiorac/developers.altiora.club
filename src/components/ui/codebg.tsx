"use client";
import { motion, animate, useMotionValue } from "motion/react";
import { useState, useEffect, useRef, ReactNode } from "react";

// Expanded code snippets with longer lines for different languages
const codeSnippets = {
	c: [
		"#define _POSIX_C_SOURCE 200809L",
		"#include <stdio.h>",
		"#include <stdlib.h>",
		"#include <stdint.h>",
		"#include <stdbool.h>",
		"#include <string.h>",
		"#include <errno.h>",
		"#include <stdarg.h>",
		"#include <ctype.h>",
		"",
		"// =============================================",
		"// 1) Arena allocator",
		"// =============================================",
		"typedef struct ArenaChunk {",
		"    struct ArenaChunk *next;",
		"    size_t cap, used;",
		"    unsigned char data[];",
		"} ArenaChunk;",
		"",
		"typedef struct Arena {",
		"    ArenaChunk *head;",
		"    size_t chunk_size;",
		"} Arena;",
		"",
		"static Arena arena_make(size_t chunk_size) {",
		"    if (chunk_size < 4096) chunk_size = 4096;",
		"    return (Arena){ .head=NULL, .chunk_size=chunk_size };",
		"}",
		"",
		"static void arena_reset(Arena *a) {",
		"    for (ArenaChunk *c=a->head; c; c=c->next) c->used = 0;",
		"}",
		"",
		"static void arena_free(Arena *a) {",
		"    ArenaChunk *c=a->head; while (c) { ArenaChunk *n=c->next; free(c); c=n; }",
		"    a->head=NULL;",
		"}",
		"",
		"static void *arena_alloc(Arena *a, size_t n, size_t align) {",
		"    if (align==0) align=8;",
		"    if (!a->head || (a->head->used + align - 1 + n) > a->head->cap) {",
		"        size_t cap = a->chunk_size > n ? a->chunk_size : n*2;",
		"        ArenaChunk *c = malloc(sizeof(ArenaChunk)+cap);",
		"        if (!c) return NULL;",
		"        c->next = a->head; c->cap = cap; c->used = 0;",
		"        a->head = c;",
		"    }",
		"    uintptr_t base = (uintptr_t)a->head->data + a->head->used;",
		"    uintptr_t p = (base + (align-1)) & ~(uintptr_t)(align-1);",
		"    size_t adv = (size_t)(p - (uintptr_t)a->head->data);",
		"    if (adv + n > a->head->cap) return NULL; // should not happen",
		"    a->head->used = adv + n;",
		"    return (void*)p;",
		"}",
		"",
		"#define ARENA_NEW(a, T) (T*)arena_alloc((a), sizeof(T), _Alignof(T))",
		"#define ARENA_ALLOC(a, T, n) (T*)arena_alloc((a), sizeof(T)*(n), _Alignof(T))",
		"",
		"// =============================================",
		"// 2) Ring buffer (byte FIFO)",
		"// =============================================",
		"typedef struct {",
		"    unsigned char *buf; size_t cap, r, w, full;",
		"} Ring;",
		"",
		"static bool ring_init(Ring *rb, size_t cap) {",
		"    rb->buf = malloc(cap); if (!rb->buf) return false;",
		"    rb->cap=cap; rb->r=rb->w=rb->full=0; return true;",
		"}",
		"static void ring_free(Ring *rb){ free(rb->buf); memset(rb,0,sizeof *rb);} ",
		"static size_t ring_size(const Ring *rb){ return rb->full? rb->cap : (rb->w+rb->cap-rb->r)%rb->cap; }",
		"static size_t ring_space(const Ring *rb){ return rb->cap - ring_size(rb); }",
		"static size_t ring_push(Ring *rb, const void *src, size_t n){",
		"    size_t wrote=0; const unsigned char *s=src;",
		"    while (wrote<n && ring_space(rb)>0){ rb->buf[rb->w]=s[wrote++]; rb->w=(rb->w+1)%rb->cap; if(rb->w==rb->r) rb->full=1; }",
		"    return wrote;",
		"}",
		"static size_t ring_pop(Ring *rb, void *dst, size_t n){",
		"    size_t read=0; unsigned char *d=dst; size_t size=ring_size(rb);",
		"    while(read<n && size>0){ d[read++]=rb->buf[rb->r]; rb->r=(rb->r+1)%rb->cap; rb->full=0; size--; }",
		"    return read;",
		"}",
		"",
		"// =============================================",
		"// 3) Hash map (string -> u64), open addressing linear probing",
		"// =============================================",
		"typedef struct { char *key; uint64_t val; bool used; } HSlot;",
		"",
		"typedef struct { HSlot *slots; size_t cap, count; } HMap;",
		"",
		"static uint64_t h_hash(const char *s){ uint64_t h=1469598103934665603ULL; while(*s){ h^=(unsigned char)(*s++); h*=1099511628211ULL;} return h; }",
		"static bool hmap_init(HMap *m, size_t cap){ size_t c=1; while(c<cap) c<<=1; m->slots=calloc(c,sizeof(HSlot)); if(!m->slots) return false; m->cap=c; m->count=0; return true; }",
		"static void hmap_free(HMap *m){ for(size_t i=0;i<m->cap;i++) free(m->slots[i].key); free(m->slots); memset(m,0,sizeof *m);} ",
		"static bool hmap_put(HMap *m, const char *key, uint64_t val){ if ((m->count+1)*2 > m->cap) return false; // no resize in this tiny impl",
		"    uint64_t h=h_hash(key); size_t i=(size_t)h & (m->cap-1);",
		"    for(;;){ HSlot *s=&m->slots[i]; if(!s->used){ s->used=true; s->key=strdup(key); if(!s->key) return false; s->val=val; m->count++; return true; } if(strcmp(s->key,key)==0){ s->val=val; return true; } i=(i+1)&(m->cap-1);} }",
		"static bool hmap_get(const HMap *m, const char *key, uint64_t *out){ uint64_t h=h_hash(key); size_t i=(size_t)h&(m->cap-1); for(;;){ HSlot s=m->slots[i]; if(!s.used) return false; if(strcmp(s.key,key)==0){ if(out) *out=s.val; return true; } i=(i+1)&(m->cap-1);} }",
		"",
		"// =============================================",
		"// 4) Logger",
		"// =============================================",
		"typedef enum { LOG_DEBUG, LOG_INFO, LOG_WARN, LOG_ERROR } LogLevel;",
		"",
		"typedef struct { FILE *fp; LogLevel level; } Logger;",
		"",
		"static const char* log_level_str(LogLevel l){",
		'    switch(l){ case LOG_DEBUG: return "DEBUG"; case LOG_INFO: return "INFO"; case LOG_WARN: return "WARN"; default: return "ERROR"; }',
		"}",
		"",
		"static void log_msg(Logger *lg, LogLevel lvl, const char *fmt, ...) {",
		"    if (!lg || lvl < lg->level) return; ",
		"    va_list ap; va_start(ap, fmt);",
		'    fprintf(lg->fp?lg->fp:stderr, "[%s] ", log_level_str(lvl));',
		"    vfprintf(lg->fp?lg->fp:stderr, fmt, ap);",
		"    fputc('\n', lg->fp?lg->fp:stderr);",
		"    va_end(ap);",
		"}",
		"",
		"// =============================================",
		"// 5) CLI arg parser: supports -v, --verbose, key=value",
		"// =============================================",
		"typedef struct { bool verbose; const char *ini_path; const char *input; } CLI;",
		"",
		"static CLI cli_parse(int argc, char **argv){",
		"    CLI c = {0};",
		"    for (int i=1; i<argc; i++){",
		"        char *a = argv[i];",
		'        if (strcmp(a, "-v")==0 || strcmp(a, "--verbose")==0) c.verbose=true;',
		'        else if (strncmp(a, "ini=", 4)==0) c.ini_path=a+4;',
		"        else if (!c.input) c.input=a; ",
		"    }",
		"    return c;",
		"}",
		"",
		"// =============================================",
		"// 6) UTFâ€‘8 validation & rune iter",
		"// =============================================",
		"static bool utf8_valid(const unsigned char *s, size_t n){",
		"    for(size_t i=0;i<n;){",
		"        unsigned char c=s[i]; size_t need=0; uint32_t cp=0;",
		"        if (c<0x80){ i++; continue; }",
		"        else if ((c&0xE0)==0xC0){ need=1; cp=c&0x1F; if(cp<2) return false; }",
		"        else if ((c&0xF0)==0xE0){ need=2; cp=c&0x0F; }",
		"        else if ((c&0xF8)==0xF0){ need=3; cp=c&0x07; if (cp>4) return false; }",
		"        else return false;",
		"        if (i+need>=n) return false;",
		"        for(size_t j=1;j<=need;j++){ if ((s[i+j]&0xC0)!=0x80) return false; cp=(cp<<6)|(s[i+j]&0x3F);} ",
		"        i+=need+1;",
		"    }",
		"    return true;",
		"}",
		"",
		"// =============================================",
		"// 7) Minimal INI reader (no escapes). Reuses Arena for strings.",
		"// =============================================",
		"typedef struct { const char *section; const char *key; const char *val; } INIEntry;",
		"",
		"typedef struct { INIEntry *v; size_t len; } INI;",
		"",
		"static char *arena_strdup(Arena *a, const char *s){ size_t n=strlen(s)+1; char *p=arena_alloc(a,n,1); if(!p) return NULL; memcpy(p,s,n); return p; }",
		"",
		"static INI ini_parse(Arena *a, const char *text){",
		'    INI out={0}; const char *cur_section=""; size_t cap=0;',
		"    const char *p=text;",
		"    while(*p){",
		"        while(*p && (*p=='\r' || *p=='\n')) p++;",
		"        if(!*p) break;",
		"        if(*p==';' || *p=='#'){ while(*p && *p!='\n') p++; continue; }",
		"        if(*p=='['){",
		"            const char *b=++p; while(*p && *p!=']') p++; size_t n=p-b; char tmp[256];",
		"            if(n>=sizeof tmp) n=sizeof tmp-1; memcpy(tmp,b,n); tmp[n]='\0'; cur_section=arena_strdup(a,tmp);",
		"            while(*p && *p!='\n') p++; continue;",
		"        }",
		"        const char *k=p; while(*p && *p!='=' && *p!='\n') p++; if(*p!='='){ while(*p && *p!='\n') p++; continue; }",
		"        size_t kn=p-k; char kbuf[256]; if(kn>=sizeof kbuf) kn=sizeof kbuf-1; memcpy(kbuf,k,kn); kbuf[kn]='\0';",
		"        p++; const char *v=p; while(*p && *p!='\n') p++; size_t vn=p-v; while(vn>0 && isspace((unsigned char)v[vn-1])) vn--; char vbuf[512]; if(vn>=sizeof vbuf) vn=sizeof vbuf-1; memcpy(vbuf,v,vn); vbuf[vn]='\0';",
		"        if(out.len==cap){ cap=cap?cap*2:16; out.v=realloc(out.v,cap*sizeof *out.v); }",
		"        out.v[out.len++] = (INIEntry){ arena_strdup(a,cur_section), arena_strdup(a,kbuf), arena_strdup(a,vbuf) };",
		"    }",
		"    return out;",
		"}",
		"",
		"static const char* ini_get(const INI *ini, const char *section, const char *key){",
		"    for(size_t i=0;i<ini->len;i++){ if(strcmp(ini->v[i].section,section)==0 && strcmp(ini->v[i].key,key)==0) return ini->v[i].val; }",
		"    return NULL;",
		"}",
		"",
		"static void ini_free(INI *ini){ free(ini->v); ini->v=NULL; ini->len=0; }",
		"",
		"// =============================================",
		"// 8) CRC32 + Base64",
		"// =============================================",
		"static uint32_t crc32(const void *data, size_t n){",
		"    static uint32_t T[256]; static bool init=false; if(!init){ for(unsigned i=0;i<256;i++){ uint32_t c=i; for(int j=0;j<8;j++) c=(c&1)?0xEDB88320U^(c>>1):(c>>1); T[i]=c;} init=true; }",
		"    uint32_t c=~0u; const unsigned char *p=data; for(size_t i=0;i<n;i++) c=T[(c^p[i])&0xFF]^(c>>8); return ~c;",
		"}",
		"",
		'static const char B64[] = "ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/";',
		"static char *b64_encode(const void *data, size_t n, Arena *a){",
		"    size_t out_len = ((n+2)/3)*4; char *out = arena_alloc(a, out_len+1, 1); if(!out) return NULL;",
		"    const unsigned char *p=data; size_t j=0; for(size_t i=0;i<n;i+=3){ unsigned v=p[i]<<16 | (i+1<n?p[i+1]<<8:0) | (i+2<n?p[i+2]:0); out[j++]=B64[(v>>18)&63]; out[j++]=B64[(v>>12)&63]; out[j++]=(i+1<n)?B64[(v>>6)&63]:'='; out[j++]=(i+2<n)?B64[v&63]:'='; } out[j]=''; return out; }",
		"",
		"// =============================================",
		"// 9) File utils",
		"// =============================================",
		"static char *file_slurp(const char *path, size_t *out_n){",
		'    FILE *f=fopen(path,"rb"); if(!f) return NULL; if(fseek(f,0,SEEK_END)!=0){ fclose(f); return NULL;} long sz=ftell(f); if(sz<0){ fclose(f); return NULL;} rewind(f);',
		"    char *buf=malloc((size_t)sz+1); if(!buf){ fclose(f); return NULL; }",
		"    size_t n=fread(buf,1,(size_t)sz,f); fclose(f); buf[n]='\0'; if(out_n) *out_n=n; return buf;",
		"}",
		"",
		'static bool file_write_all(const char *path, const void *data, size_t n){ FILE *f=fopen(path,"wb"); if(!f) return false; size_t w=fwrite(data,1,n,f); fclose(f); return w==n; }',
		"",
		"// =============================================",
		"// Demo program",
		"// =============================================",
		"int main(int argc, char **argv){",
		"    CLI cli = cli_parse(argc, argv);",
		"    Logger lg = { .fp = stderr, .level = cli.verbose ? LOG_DEBUG : LOG_INFO };",
		"",
		"    if (!cli.input) {",
		'        fprintf(stderr, "Usage: %s [-v|--verbose] ini=path/to/config.ini <input-file>\n", argv[0]);',
		"        return 2;",
		"    }",
		"",
		'    log_msg(&lg, LOG_INFO, "Reading input: %s", cli.input);',
		"    size_t in_n=0; char *in = file_slurp(cli.input, &in_n);",
		"    if (!in) { log_msg(&lg, LOG_ERROR, \"Failed to read '%s': %s\", cli.input, strerror(errno)); return 1; }",
		"",
		"    // Validate UTFâ€‘8",
		"    bool valid = utf8_valid((unsigned char*)in, in_n);",
		'    log_msg(&lg, LOG_INFO, "UTF-8 valid: %s", valid?"yes":"no");',
		"",
		"    // Compute CRC and Base64 it",
		"    Arena scratch = arena_make(16*1024);",
		"    uint32_t crc = crc32(in, in_n);",
		'    char crc_msg[64]; snprintf(crc_msg, sizeof crc_msg, "crc32=0x%08X", crc);',
		"    char *crc_b64 = b64_encode(crc_msg, strlen(crc_msg), &scratch);",
		'    log_msg(&lg, LOG_DEBUG, "%s (b64=%s)", crc_msg, crc_b64);',
		"",
		"    // Load INI if provided",
		"    INI ini={0};",
		"    if (cli.ini_path){",
		"        size_t n=0; char *txt=file_slurp(cli.ini_path,&n);",
		'        if(!txt) log_msg(&lg, LOG_WARN, "No INI loaded: %s", strerror(errno));',
		'        else { ini = ini_parse(&scratch, txt); free(txt); const char *lvl=ini_get(&ini, "log", "level"); if(lvl){ if(strcmp(lvl,"debug")==0) lg.level=LOG_DEBUG; if(strcmp(lvl,"warn")==0) lg.level=LOG_WARN; if(strcmp(lvl,"error")==0) lg.level=LOG_ERROR; }',
		'            const char *sink=ini_get(&ini, "log", "file"); if(sink && *sink){ FILE *fp=fopen(sink, "a"); if(fp){ lg.fp=fp; log_msg(&lg, LOG_INFO, "Logging to %s", sink);} else log_msg(&lg, LOG_WARN, "Failed to open log sink %s: %s", sink, strerror(errno)); }',
		"        }",
		"    }",
		"",
		"    // Build frequency index using hashmap",
		'    HMap map; if(!hmap_init(&map, 1024)){ log_msg(&lg, LOG_ERROR, "Out of memory"); return 1; }',
		"    size_t words=0; for(char *p=in; *p;){ while(*p && !isalnum((unsigned char)*p)) p++; if(!*p) break; char *b=p; while(*p && isalnum((unsigned char)*p)) p++; size_t n=p-b; char key[128]; if(n>=sizeof key) n=sizeof key-1; memcpy(key,b,n); key[n]='\0'; for(size_t i=0;i<n;i++) key[i]=(char)tolower((unsigned char)key[i]);",
		"        uint64_t v=0; if(hmap_get(&map,key,&v)) hmap_put(&map,key,v+1); else hmap_put(&map,key,1); words++; }",
		'    log_msg(&lg, LOG_INFO, "Indexed %zu words", words);',
		"",
		"    // Stream input through ring buffer as an example pipe",
		"    Ring rb; ring_init(&rb, 4096);",
		"    size_t pushed=0; pushed += ring_push(&rb, in, in_n);",
		"    unsigned char temp[1024]; size_t popped=0; popped += ring_pop(&rb, temp, sizeof temp);",
		'    log_msg(&lg, LOG_DEBUG, "Ring: pushed=%zu popped=%zu left=%zu", pushed, popped, ring_size(&rb));',
		"",
		"    // Emit a small report file using arena formatting",
		'    const char *out_path = ini_get(&ini, "output", "report"); if(!out_path) out_path = "report.txt";',
		"    char *report = arena_alloc(&scratch, 4096, 1); size_t rlen=0;",
		'    rlen += (size_t)snprintf(report+rlen, 4096-rlen, "Report for %s\n", cli.input);',
		'    rlen += (size_t)snprintf(report+rlen, 4096-rlen, "UTF8: %s\nCRC32: 0x%08X\nCRC32(b64): %s\n", valid?"ok":"invalid", crc, crc_b64);',
		'    rlen += (size_t)snprintf(report+rlen, 4096-rlen, "Unique words (sample up to 20):\n");',
		'    size_t shown=0; for(size_t i=0; i<map.cap && shown<20; i++){ if(map.slots[i].used){ rlen += (size_t)snprintf(report+rlen, 4096-rlen, "  %-16s : %llu\n", map.slots[i].key, (unsigned long long)map.slots[i].val); shown++; } }',
		"    file_write_all(out_path, report, rlen);",
		'    log_msg(&lg, LOG_INFO, "Wrote %s", out_path);',
		"",
		"    // Cleanup",
		"    if (lg.fp && lg.fp!=stderr) fclose(lg.fp);",
		"    ring_free(&rb); hmap_free(&map); free(in); ini_free(&ini); arena_free(&scratch);",
		"    return 0;",
		"}",
	],
	cpp: [
		"#include <bits/stdc++.h>",
		"#include <chrono>",
		"#include <filesystem>",
		"#include <fstream>",
		"#include <mutex>",
		"#include <shared_mutex>",
		"#include <thread>",
		"",
		"using namespace std;",
		"namespace fs = std::filesystem;",
		"",
		"// Simple fixed-size ring buffer for numeric samples",
		"template <typename T>",
		"class RingBuffer {",
		"public:",
		"    explicit RingBuffer(size_t capacity = 1024)",
		"        : capacity_(max<size_t>(1, capacity)), data_(capacity_), head_(0), size_(0) {}",
		"",
		"    void push(const T& value) {",
		"        data_[head_] = value;",
		"        head_ = (head_ + 1) % capacity_;",
		"        if (size_ < capacity_) ++size_;",
		"    }",
		"",
		"    vector<T> last_n(size_t n) const {",
		"        n = min(n, size_);",
		"        vector<T> out;",
		"        out.reserve(n);",
		"        size_t idx = (head_ + capacity_ - 1) % capacity_;",
		"        for (size_t i = 0; i < n; ++i) {",
		"            out.push_back(data_[idx]);",
		"            idx = (idx + capacity_ - 1) % capacity_;",
		"        }",
		"        reverse(out.begin(), out.end());",
		"        return out;",
		"    }",
		"",
		"    vector<T> to_vector() const {",
		"        return last_n(size_);",
		"    }",
		"",
		"    size_t size() const { return size_; }",
		"    size_t capacity() const { return capacity_; }",
		"",
		"    void resize(size_t new_capacity) {",
		"        if (new_capacity == 0) new_capacity = 1;",
		"        vector<T> current = to_vector();",
		"        capacity_ = new_capacity;",
		"        data_.assign(capacity_, T{});",
		"        head_ = 0; size_ = 0;",
		"        size_t start = current.size() > capacity_ ? current.size() - capacity_ : 0;",
		"        for (size_t i = start; i < current.size(); ++i) push(current[i]);",
		"    }",
		"",
		"private:",
		"    size_t capacity_;",
		"    vector<T> data_;",
		"    size_t head_;",
		"    size_t size_;",
		"};",
		"",
		"struct Sample {",
		"    double value{};",
		"    chrono::system_clock::time_point tp{};",
		"};",
		"",
		"struct Metric {",
		"    string name;",
		"    RingBuffer<Sample> buffer;",
		"    explicit Metric(string n = {}, size_t window = 1024) : name(move(n)), buffer(window) {}",
		"};",
		"",
		"class MetricStore {",
		"public:",
		"    explicit MetricStore(size_t default_window = 2048)",
		"        : default_window_(default_window) {}",
		"",
		"    void put(const string& key, double value) {",
		"        auto now = chrono::system_clock::now();",
		"        unique_lock lk(mu_);",
		"        auto& m = get_or_create_unlocked(key);",
		"        m.buffer.push(Sample{value, now});",
		"        touch_unlocked(key);",
		"    }",
		"",
		"    vector<Sample> get_last(const string& key, size_t n) const {",
		"        shared_lock lk(mu_);",
		"        auto it = metrics_.find(key);",
		"        if (it == metrics_.end()) return {};",
		"        return it->second.buffer.last_n(n);",
		"    }",
		"",
		"    vector<string> keys() const {",
		"        shared_lock lk(mu_);",
		"        vector<string> out; out.reserve(metrics_.size());",
		"        for (auto& [k, _] : metrics_) out.push_back(k);",
		"        return out;",
		"    }",
		"",
		"    void set_window(const string& key, size_t window) {",
		"        unique_lock lk(mu_);",
		"        auto& m = get_or_create_unlocked(key);",
		"        m.buffer.resize(window);",
		"        touch_unlocked(key);",
		"    }",
		"",
		"    size_t get_window(const string& key) const {",
		"        shared_lock lk(mu_);",
		"        auto it = metrics_.find(key);",
		"        if (it == metrics_.end()) return default_window_;",
		"        return it->second.buffer.capacity();",
		"    }",
		"",
		"    void save(const fs::path& file) const {",
		"        shared_lock lk(mu_);",
		"        ofstream out(file, ios::binary);",
		'        if (!out) throw runtime_error("Cannot open file for writing: " + file.string());',
		"        // format: line per sample => name\    epoch_ms\    value",
		"        for (auto& [name, metric] : metrics_) {",
		"            auto vec = metric.buffer.to_vector();",
		"            for (auto& s : vec) {",
		"                auto ms = chrono::duration_cast<chrono::milliseconds>(s.tp.time_since_epoch()).count();",
		"                out << name << '\    ' << ms << '\    ' << std::setprecision(17) << s.value << '\\n';",
		"            }",
		"        }",
		"    }",
		"",
		"    void load(const fs::path& file) {",
		"        ifstream in(file, ios::binary);",
		'        if (!in) throw runtime_error("Cannot open file for reading: " + file.string());',
		"        unordered_map<string, vector<Sample>> tmp;",
		"        string name; long long ms; double v;",
		"        string line;",
		"        while (getline(in, line)) {",
		"            if (line.empty()) continue;",
		"            // parse tab separated",
		"            size_t p1 = line.find('\    '); if (p1 == string::npos) continue;",
		"            size_t p2 = line.find('\    ', p1 + 1); if (p2 == string::npos) continue;",
		"            name = line.substr(0, p1);",
		"            ms = atoll(line.substr(p1 + 1, p2 - p1 - 1).c_str());",
		"            v = atof(line.substr(p2 + 1).c_str());",
		"            Sample s{v, chrono::system_clock::time_point{chrono::milliseconds{ms}}};",
		"            tmp[name].push_back(s);",
		"        }",
		"        unique_lock lk(mu_);",
		"        for (auto& [k, vec] : tmp) {",
		"            auto& m = get_or_create_unlocked(k);",
		"            // ensure chronological order",
		"            sort(vec.begin(), vec.end(), [](const Sample& a, const Sample& b){ return a.tp < b.tp; });",
		"            for (auto& s : vec) m.buffer.push(s);",
		"            touch_unlocked(k);",
		"        }",
		"    }",
		"",
		"    vector<pair<string, double>> topk_mean(size_t k, size_t last_n = 0) const {",
		"        shared_lock lk(mu_);",
		"        vector<pair<string, double>> scores;",
		"        scores.reserve(metrics_.size());",
		"        for (auto& [name, metric] : metrics_) {",
		"            auto vec = last_n ? metric.buffer.last_n(last_n) : metric.buffer.to_vector();",
		"            if (vec.empty()) continue;",
		"            double sum = 0.0; for (auto& s : vec) sum += s.value;",
		"            scores.emplace_back(name, sum / vec.size());",
		"        }",
		"        sort(scores.begin(), scores.end(), [](auto& a, auto& b){ return a.second > b.second; });",
		"        if (k < scores.size()) scores.resize(k);",
		"        return scores;",
		"    }",
		"",
		"    size_t size() const {",
		"        shared_lock lk(mu_); return metrics_.size();",
		"    }",
		"",
		"private:",
		"    Metric& get_or_create_unlocked(const string& key) const {",
		"        auto it = metrics_.find(key);",
		"        if (it == metrics_.end()) {",
		"            auto [nit, _] = metrics_.emplace(key, Metric{key, default_window_});",
		"            return nit->second;",
		"        }",
		"        return it->second;",
		"    }",
		"",
		"    void touch_unlocked(const string& key) const {",
		"        lru_list_.remove(key);",
		"        lru_list_.push_front(key);",
		"        if (lru_list_.size() > lru_capacity_) {",
		"            // optional: evict oldest metric entirely",
		"            auto victim = lru_list_.back();",
		"            lru_list_.pop_back();",
		"            metrics_.erase(victim);",
		"        }",
		"    }",
		"",
		"    size_t default_window_;",
		"    mutable unordered_map<string, Metric> metrics_;",
		"    mutable list<string> lru_list_;",
		"    size_t lru_capacity_ = 10000; // maximum number of distinct metrics retained",
		"    mutable shared_mutex mu_;",
		"};",
		"",
		"// Utility functions",
		"static inline vector<string> split(const string& s) {",
		"    vector<string> out; string cur; bool in_quote=false; char qc='\"';",
		"    for (size_t i=0;i<s.size();++i){",
		"        char c=s[i];",
		"        if ((c=='\"' || c=='\\'') && (i==0 || s[i-1] != '\\\\')) { in_quote = !in_quote; qc=c; continue; }",
		"        if (!in_quote && isspace(static_cast<unsigned char>(c))) { if(!cur.empty()){ out.push_back(cur); cur.clear(); } }",
		"        else if (c=='\"' || c=='\\'') cur.push_back(c); // keep quotes inside tokens",
		"        else cur.push_back(c);",
		"    }",
		"    if(!cur.empty()) out.push_back(cur);",
		"    return out;",
		"}",
		"",
		"static inline string now_iso8601() {",
		"    using namespace chrono;",
		"    auto tp = system_clock::now();",
		"    time_t t = system_clock::to_time_t(tp);",
		"    tm tm{};",
		"#ifdef _WIN32",
		"    gmtime_s(&tm, &t);",
		"#else",
		"    gmtime_r(&t, &tm);",
		"#endif",
		"    char buf[64];",
		'    strftime(buf, sizeof(buf), "%Y-%m-%dT%H:%M:%SZ", &tm);',
		"    return string(buf);",
		"}",
		"",
		"struct StatResult {",
		"    double mean = NAN;",
		"    double stddev = NAN;",
		"    double min = NAN;",
		"    double max = NAN;",
		"    optional<double> percentile; // if requested",
		"};",
		"",
		"static StatResult compute_stats(const vector<Sample>& vec, optional<double> pct) {",
		"    StatResult r;",
		"    if (vec.empty()) return r;",
		"    double sum = 0.0, sumsq = 0.0; r.min = numeric_limits<double>::infinity(); r.max = -r.min;",
		"    vector<double> vals; vals.reserve(vec.size());",
		"    for (auto& s : vec) {",
		"        sum += s.value; sumsq += s.value * s.value; r.min = min(r.min, s.value); r.max = max(r.max, s.value); vals.push_back(s.value);",
		"    }",
		"    r.mean = sum / vals.size();",
		"    double var = max(0.0, sumsq / vals.size() - r.mean * r.mean);",
		"    r.stddev = sqrt(var);",
		"    if (pct) {",
		"        sort(vals.begin(), vals.end());",
		"        double p = *pct; if (p < 0) p = 0; if (p > 100) p = 100;",
		"        double idx = (p/100.0) * (vals.size() - 1);",
		"        size_t lo = floor(idx), hi = ceil(idx);",
		"        double frac = idx - lo;",
		"        r.percentile = vals[lo] * (1 - frac) + vals[hi] * frac;",
		"    }",
		"    return r;",
		"}",
		"",
		"static void print_stats(const string& key, const vector<Sample>& vec, optional<double> p) {",
		"    auto r = compute_stats(vec, p);",
		"    cout.setf(std::ios::fixed); cout << setprecision(6);",
		'    cout << "metric: " << key << "\\n";',
		'    cout << "count=" << vec.size() << " mean=" << r.mean << " stddev=" << r.stddev',
		'         << " min=" << r.min << " max=" << r.max;',
		'    if (r.percentile) cout << " p=" << *p << "%=" << *r.percentile;',
		'    cout << "\\n";',
		"}",
		"",
		"static void export_csv(const fs::path& out_path, const string& key, const vector<Sample>& vec) {",
		"    ofstream out(out_path);",
		'    if (!out) throw runtime_error("Cannot write: " + out_path.string());',
		'    out << "timestamp_iso,value\\n";',
		"    for (auto& s : vec) {",
		"        // ISO string for readability",
		"        time_t t = chrono::system_clock::to_time_t(s.tp);",
		"        tm tm{};",
		"#ifdef _WIN32",
		"        gmtime_s(&tm, &t);",
		"#else",
		"        gmtime_r(&t, &tm);",
		"#endif",
		"        char buf[64];",
		'        strftime(buf, sizeof(buf), "%Y-%m-%dT%H:%M:%SZ", &tm);',
		'        out << buf << "," << std::setprecision(17) << s.value << "\\n";',
		"    }",
		"}",
		"",
		"static void print_help() {",
		'    cout << "commands:\\n"',
		'         << "  put <name> <value>                 - add a sample\\n"',
		'         << "  stat <name> [last=N] [p=95]       - show statistics\\n"',
		'         << "  topk <k> [last=N]                 - highest mean metrics\\n"',
		'         << "  export <name|*> <path> [last=N]   - write CSV(s)\\n"',
		'         << "  window <name> <size>               - set retention\\n"',
		'         << "  save <path>                        - persist all samples\\n"',
		'         << "  load <path>                        - load samples\\n"',
		'         << "  keys                               - list metric names\\n"',
		'         << "  help                               - show this help\\n"',
		'         << "  quit                               - exit\\n";',
		"}",
		"",
		"int main(int argc, char** argv) {",
		"    ios::sync_with_stdio(false);",
		"    cin.tie(nullptr);",
		"    MetricStore store(4096);",
		"",
		"    // optional preload file path",
		"    if (argc > 1) {",
		'        try { store.load(argv[1]); cerr << "loaded from " << argv[1] << "\\n"; }',
		'        catch (const exception& e) { cerr << e.what() << "\\n"; }',
		"    }",
		"",
		'    cout << "metricd " << now_iso8601() << "\\n";',
		"    print_help();",
		"",
		"    string line;",
		"    while (true) {",
		'        cout << "> " << flush;',
		"        if (!getline(cin, line)) break;",
		"        if (line.empty()) continue;",
		"        auto tokens = split(line);",
		"        if (tokens.empty()) continue;",
		"        string cmd = tokens[0];",
		"",
		"        try {",
		'            if (cmd == "put" && tokens.size() >= 3) {',
		"                string name = tokens[1];",
		"                double v = stod(tokens[2]);",
		"                store.put(name, v);",
		'                cout << "ok\\n";',
		'            } else if (cmd == "stat" && tokens.size() >= 2) {',
		"                string name = tokens[1];",
		"                size_t last = 0; optional<double> p;",
		"                for (size_t i = 2; i < tokens.size(); ++i) {",
		'                    if (tokens[i].rfind("last=", 0) == 0) last = stoull(tokens[i].substr(5));',
		'                    else if (tokens[i].rfind("p=", 0) == 0) p = stod(tokens[i].substr(2));',
		"                }",
		"                auto vec = last ? store.get_last(name, last) : store.get_last(name, store.get_window(name));",
		"                print_stats(name, vec, p);",
		'            } else if (cmd == "topk" && tokens.size() >= 2) {',
		"                size_t k = stoull(tokens[1]); size_t last = 0;",
		'                for (size_t i = 2; i < tokens.size(); ++i) if (tokens[i].rfind("last=", 0) == 0) last = stoull(tokens[i].substr(5));',
		"                auto scores = store.topk_mean(k, last);",
		"                cout.setf(ios::fixed); cout << setprecision(6);",
		'                for (auto& [name, mean] : scores) cout << name << "\    " << mean << "\\n";',
		'            } else if (cmd == "export" && tokens.size() >= 3) {',
		"                string key = tokens[1]; fs::path out = tokens[2]; size_t last = 0;",
		'                for (size_t i = 3; i < tokens.size(); ++i) if (tokens[i].rfind("last=", 0) == 0) last = stoull(tokens[i].substr(5));',
		'                if (key == "*") {',
		"                    for (auto& kname : store.keys()) {",
		"                        auto vec = last ? store.get_last(kname, last) : store.get_last(kname, store.get_window(kname));",
		'                        fs::path p = out / (kname + ".csv");',
		"                        export_csv(p, kname, vec);",
		"                    }",
		"                } else {",
		"                    auto vec = last ? store.get_last(key, last) : store.get_last(key, store.get_window(key));",
		"                    export_csv(out, key, vec);",
		"                }",
		'                cout << "written\\n";',
		'            } else if (cmd == "window" && tokens.size() >= 3) {',
		"                store.set_window(tokens[1], stoull(tokens[2]));",
		'                cout << "ok\\n";',
		'            } else if (cmd == "save" && tokens.size() >= 2) {',
		'                store.save(tokens[1]); cout << "saved\\n";',
		'            } else if (cmd == "load" && tokens.size() >= 2) {',
		'                store.load(tokens[1]); cout << "loaded\\n";',
		'            } else if (cmd == "keys") {',
		"                auto ks = store.keys();",
		"                sort(ks.begin(), ks.end());",
		"                for (auto& k : ks) cout << k << '\\n';",
		'            } else if (cmd == "help") {',
		"                print_help();",
		'            } else if (cmd == "quit" || cmd == "exit") {',
		"                break;",
		"            } else {",
		'                cout << "? unknown\\n"; ',
		"            }",
		"        } catch (const exception& e) {",
		'            cout << "error: " << e.what() << "\\n";',
		"        }",
		"    }",
		"",
		"    return 0;",
		"}",
	],
	react: [
		`import React, { useEffect, useMemo, useReducer, useRef, useState } from "react";`,
		`import { motion, AnimatePresence } from "framer-motion";`,
		`import { LineChart, Line, XAxis, YAxis, ResponsiveContainer, Tooltip as RechartsTooltip, CartesianGrid, AreaChart, Area } from "recharts";`,
		`import { Search, Plus, CheckCircle2, Circle, Calendar, BarChart3, FolderKanban, Settings, X, Clock, Filter, Sparkles, ChevronRight, Upload, Play, Pause, Trash2, ArrowUpRight, Tag } from "lucide-react";`,
		`import { Button } from "@/components/ui/button";`,
		`import { Card, CardContent, CardDescription, CardHeader, CardTitle } from "@/components/ui/card";`,
		`import { Input } from "@/components/ui/input";`,
		`import { Tabs, TabsList, TabsTrigger, TabsContent } from "@/components/ui/tabs";`,
		`import { Badge } from "@/components/ui/badge";`,
		`import { DropdownMenu, DropdownMenuContent, DropdownMenuItem, DropdownMenuLabel, DropdownMenuSeparator, DropdownMenuTrigger } from "@/components/ui/dropdown-menu";`,
		`import { Dialog, DialogContent, DialogHeader, DialogTitle, DialogTrigger } from "@/components/ui/dialog";`,
		`import { Progress } from "@/components/ui/progress";`,
		`import { Switch } from "@/components/ui/switch";`,
		`import { Slider } from "@/components/ui/slider";`,
		``,
		`function useLocalStorage(key, initialValue) {`,
		`  const [value, setValue] = useState(() => {`,
		`    try { const v = window.localStorage.getItem(key); return v ? JSON.parse(v) : initialValue } catch { return initialValue }`,
		`  })`,
		`  useEffect(() => { try { window.localStorage.setItem(key, JSON.stringify(value)) } catch {} }, [key, value])`,
		`  return [value, setValue]`,
		`}`,
		``,
		`const seedProjects = () => ([`,
		`  { id: "p1", name: "Rune Editor", color: "#7c3aed", tags: ["rust", "tui"], createdAt: Date.now() - 1000*60*60*24*12 },`,
		`  { id: "p2", name: "Hex Debugger", color: "#f59e0b", tags: ["c", "debug"], createdAt: Date.now() - 1000*60*60*24*30 },`,
		`  { id: "p3", name: "Forge Build", color: "#10b981", tags: ["rust", "build"], createdAt: Date.now() - 1000*60*60*24*3 },`,
		`])`,
		``,
		`function reducer(state, action) {`,
		`  switch(action.type){`,
		`    case "add-task": {`,
		`      const tasks = [...state.tasks, action.task]`,
		`      return { ...state, tasks }`,
		`    }`,
		`    case "toggle-task": {`,
		`      const tasks = state.tasks.map(t => t.id === action.id ? { ...t, done: !t.done, completedAt: !t.done ? Date.now() : null } : t)`,
		`      return { ...state, tasks }`,
		`    }`,
		`    case "delete-task": {`,
		`      const tasks = state.tasks.filter(t => t.id !== action.id)`,
		`      return { ...state, tasks }`,
		`    }`,
		`    case "select-project": return { ...state, selectedProject: action.id }`,
		`    case "hydrate": return action.state`,
		`    default: return state`,
		`  }`,
		`}`,
		``,
		`const initialState = {`,
		`  tasks: [`,
		`    { id: "t1", title: "Implement syntax highlighter", projectId: "p1", estimate: 3, done: false, tags:["frontend","parser"], createdAt: Date.now()-1000*60*60*8 },`,
		`    { id: "t2", title: "Add step-through breakpoints", projectId: "p2", estimate: 5, done: true, completedAt: Date.now()-1000*60*60*24, tags:["debug"], createdAt: Date.now()-1000*60*60*60 },`,
		`    { id: "t3", title: "Design build graph view", projectId: "p3", estimate: 2, done: false, tags:["ui","graph"], createdAt: Date.now()-1000*60*60*2 },`,
		`  ],`,
		`  selectedProject: "p3",`,
		`}`,
		``,
		`function useHotkeys(map){`,
		`  useEffect(() => {`,
		`    const handler = (e) => {`,
		`      const key = [e.ctrlKey?"Ctrl":null, e.metaKey?"Meta":null, e.shiftKey?"Shift":null, e.key.toUpperCase()].filter(Boolean).join("+")`,
		`      if(map[key]){ e.preventDefault(); map[key]() }`,
		`    }`,
		`    window.addEventListener("keydown", handler)`,
		`    return () => window.removeEventListener("keydown", handler)`,
		`  }, [JSON.stringify(Object.keys(map))])`,
		`}`,
		``,
		`function ProjectBadge({name, color}){`,
		`  return (`,
		`    <span className=\"inline-flex items-center gap-1 rounded-full px-2 py-0.5 text-xs\" style={{backgroundColor: \`\${color}1A\`, color}}>`,
		`      <FolderKanban className=\"h-3 w-3\" /> {name}`,
		`    </span>`,
		`  )`,
		`}`,
		``,
		`function Timer({ running, seconds, onToggle }){`,
		`  const mins = Math.floor(seconds/60).toString().padStart(2,\"0\")`,
		`  const secs = (seconds%60).toString().padStart(2,\"0\")`,
		`  return (`,
		`    <div className=\"flex items-center gap-3\">`,
		`      <div className=\"font-mono text-xl tabular-nums\">{mins}:{secs}</div>`,
		`      <Button size=\"sm\" onClick={onToggle} className=\"rounded-2xl\">{running ? <>`,
		`        <Pause className=\"mr-1 h-4 w-4\"/>Pause</> : <>`,
		`        <Play className=\"mr-1 h-4 w-4\"/>Start</>}</Button>`,
		`    </div>`,
		`  )`,
		`}`,
		``,
		`function Sparkline({data}){`,
		`  return (`,
		`    <ResponsiveContainer width=\"100%\" height={80}>`,
		`      <AreaChart data={data} margin={{ top: 8, right: 12, left: 0, bottom: 0 }}>`,
		`        <defs>`,
		`          <linearGradient id=\"g\" x1=\"0\" y1=\"0\" x2=\"0\" y2=\"1\">`,
		`            <stop offset=\"5%\" stopColor=\"currentColor\" stopOpacity={0.3}/>`,
		`            <stop offset=\"95%\" stopColor=\"currentColor\" stopOpacity={0}/>`,
		`          </linearGradient>`,
		`        </defs>`,
		`        <CartesianGrid strokeOpacity={0.08} vertical={false}/>`,
		`        <XAxis dataKey=\"d\" hide/>`,
		`        <YAxis hide/>`,
		`        <RechartsTooltip formatter={(v)=>[\`${"${v}"} pts\`, \"Velocity\"]} labelClassName=\"text-xs\"/>`,
		`        <Area type=\"monotone\" dataKey=\"v\" stroke=\"currentColor\" fillOpacity={1} fill=\"url(#g)\" strokeWidth={2} />`,
		`      </AreaChart>`,
		`    </ResponsiveContainer>`,
		`  )`,
		`}`,
		``,
		`function CommandBar({open, setOpen, actions}){`,
		`  const [q,setQ] = useState(\"\")`,
		`  const filtered = useMemo(()=>actions.filter(a=>a.title.toLowerCase().includes(q.toLowerCase())),[q,actions])`,
		`  return (`,
		`    <AnimatePresence>`,
		`      {open && (`,
		`        <motion.div initial={{opacity:0}} animate={{opacity:1}} exit={{opacity:0}} className=\"fixed inset-0 z-50 grid place-items-start pt-24 backdrop-blur-sm\">`,
		`          <motion.div initial={{y:20,opacity:0}} animate={{y:0,opacity:1}} exit={{y:10,opacity:0}} className=\"mx-auto w-full max-w-xl rounded-2xl border bg-background p-4 shadow-2xl\">`,
		`            <div className=\"flex items-center gap-2 border-b pb-2\">`,
		`              <Search className=\"h-4 w-4 opacity-60\"/>`,
		`              <Input autoFocus value={q} onChange={(e)=>setQ(e.target.value)} placeholder=\"Type a command...\"/>`,
		`              <Button variant=\"ghost\" size=\"icon\" onClick={()=>setOpen(false)}><X className=\"h-4 w-4\"/></Button>`,
		`            </div>`,
		`            <div className=\"mt-2 max-h-60 space-y-1 overflow-auto\">`,
		`              {filtered.map((a)=> (`,
		`                <button key={a.id} onClick={()=>{a.run(); setOpen(false)}} className=\"flex w-full items-center justify-between rounded-lg px-2 py-2 text-left hover:bg-muted\">`,
		`                  <div className=\"flex items-center gap-2\"><ChevronRight className=\"h-4 w-4 opacity-60\"/>{a.title}</div>`,
		`                  {a.kbd && <kbd className=\"rounded bg-muted px-2 py-0.5 text-xs\">{a.kbd}</kbd>}`,
		`                </button>`,
		`              ))}`,
		`              {filtered.length===0 && (<div className=\"p-3 text-sm opacity-70\">No results</div>)}`,
		`            </div>`,
		`          </motion.div>`,
		`        </motion.div>`,
		`      )}`,
		`    </AnimatePresence>`,
		`  )`,
		`}`,
		``,
		`function TaskRow({task, project, onToggle, onDelete}){`,
		`  return (`,
		`    <motion.div layout className=\"flex items-center justify-between rounded-xl border px-3 py-2\">`,
		`      <div className=\"flex items-center gap-3\">`,
		`        <button onClick={()=>onToggle(task.id)} className=\"grid h-6 w-6 place-items-center rounded-full border\">`,
		`          {task.done ? <CheckCircle2 className=\"h-4 w-4\"/> : <Circle className=\"h-4 w-4\"/>}`,
		`        </button>`,
		`        <div>`,
		`          <div className={\`text-sm font-medium \${task.done?\"line-through opacity-60\":\"\"}\`}>{task.title}</div>`,
		`          <div className=\"mt-1 flex items-center gap-2 text-xs opacity-70\">`,
		`            <ProjectBadge name={project.name} color={project.color}/>`,
		`            {task.tags.map(t => (<span key={t} className=\"inline-flex items-center gap-1 rounded-full bg-muted px-2 py-0.5\"><Tag className=\"h-3 w-3\"/>{t}</span>))}`,
		`          </div>`,
		`        </div>`,
		`      </div>`,
		`      <div className=\"flex items-center gap-2\">`,
		`        <Badge variant=\"outline\" className=\"rounded-2xl\">~{task.estimate}h</Badge>`,
		`        <Button variant=\"ghost\" size=\"icon\" onClick={()=>onDelete(task.id)}><Trash2 className=\"h-4 w-4\"/></Button>`,
		`      </div>`,
		`    </motion.div>`,
		`  )`,
		`}`,
		``,
		`export default function StudioDashboard(){`,
		`  const [projects] = useLocalStorage(\"projects\", seedProjects())`,
		`  const [state, dispatch] = useReducer(reducer, initialState)`,
		`  const [query, setQuery] = useState(\"\")`,
		`  const [tab, setTab] = useState(\"active\")`,
		`  const [barOpen, setBarOpen] = useState(false)`,
		`  const [uploadOpen, setUploadOpen] = useState(false)`,
		`  const [timerRunning, setTimerRunning] = useState(false)`,
		`  const [seconds, setSeconds] = useState(0)`,
		`  const [focusMode, setFocusMode] = useState(false)`,
		`  const [estimateScale, setEstimateScale] = useState([3])`,
		`  const fileRef = useRef(null)`,
		``,
		`  useEffect(()=>{ if(timerRunning){ const id = setInterval(()=>setSeconds(s=>s+1),1000); return ()=>clearInterval(id)} },[timerRunning])`,
		`  useHotkeys({ \"Ctrl+K\": ()=>setBarOpen(true), \"Meta+K\": ()=>setBarOpen(true) })`,
		``,
		`  const selectedProject = projects.find(p=>p.id===state.selectedProject) || projects[0]`,
		`  const projectMap = useMemo(()=>Object.fromEntries(projects.map(p=>[p.id,p])),[projects])`,
		``,
		`  const filtered = useMemo(()=> state.tasks`,
		`    .filter(t => (tab === \"active\" ? !t.done : tab === \"done\" ? t.done : true))`,
		`    .filter(t => t.title.toLowerCase().includes(query.toLowerCase()) || t.tags.some(x=>x.includes(query.toLowerCase())))`,
		`    .filter(t => t.estimate <= estimateScale[0])`,
		`    .sort((a,b)=> (a.done===b.done ? a.createdAt - b.createdAt : a.done ? 1 : -1))`,
		`  ,[state.tasks, query, tab, estimateScale])`,
		``,
		`  const velocityData = useMemo(()=>{`,
		`    const days = Array.from({length:14}).map((_,i)=>{`,
		`      const day = new Date(); day.setDate(day.getDate()-i)`,
		`      const stamp = day.toDateString()`,
		`      const v = state.tasks.filter(t=>t.completedAt && new Date(t.completedAt).toDateString()===stamp).length`,
		`      return { d: day.toLocaleDateString(undefined,{month:\"short\",day:\"numeric\"}), v }`,
		`    }).reverse()`,
		`    return days`,
		`  },[state.tasks])`,
		``,
		`  const progressPct = useMemo(()=>{`,
		`    const pTasks = state.tasks.filter(t=>t.projectId===selectedProject.id)`,
		`    const done = pTasks.filter(t=>t.done).length`,
		`    return pTasks.length ? Math.round((done/pTasks.length)*100) : 0`,
		`  },[state.tasks, selectedProject])`,
		``,
		`  const actions = [`,
		`    { id: \"new-task\", title: \"New Task\", kbd: \"N\", run: () => setUploadOpen(true) },`,
		`    { id: \"toggle-focus\", title: focusMode?\"Disable Focus Mode\":\"Enable Focus Mode\", kbd: \"F\", run: () => setFocusMode(f=>!f) },`,
		`    { id: \"start-timer\", title: timerRunning?\"Pause Timer\":\"Start Timer\", kbd: \"T\", run: () => setTimerRunning(r=>!r) },`,
		`  ]`,
		``,
		`  useHotkeys({ \"N\": ()=>setUploadOpen(true), \"F\": ()=>setFocusMode(f=>!f), \"T\": ()=>setTimerRunning(r=>!r) })`,
		``,
		`  return (`,
		`    <div className={\`mx-auto max-w-6xl p-4 \${focusMode?\"[&_*]:!rounded-none [&_*]:!shadow-none\": \"\"}\`}>`,
		`      <div className=\"mb-4 flex items-center justify-between\">`,
		`        <div className=\"flex items-center gap-3\">`,
		`          <Sparkles className=\"h-6 w-6\"/>`,
		`          <div>`,
		`            <div className=\"text-xl font-semibold\">Studio Dashboard</div>`,
		`            <div className=\"text-sm opacity-70\">Unified Workbench for Projects</div>`,
		`          </div>`,
		`        </div>`,
		`        <div className=\"flex items-center gap-2\">`,
		`          <Button variant=\"outline\" onClick={()=>setBarOpen(true)} className=\"rounded-2xl\"><Search className=\"mr-2 h-4 w-4\"/>Command</Button>`,
		`          <Button onClick={()=>setUploadOpen(true)} className=\"rounded-2xl\"><Plus className=\"mr-2 h-4 w-4\"/>New Task</Button>`,
		`        </div>`,
		`      </div>`,
		``,
		`      <div className=\"grid grid-cols-1 gap-4 md:grid-cols-5\">`,
		`        <Card className=\"md:col-span-3\">`,
		`          <CardHeader className=\"pb-2\">`,
		`            <CardTitle className=\"flex items-center gap-2\"><BarChart3 className=\"h-5 w-5\"/>Team Velocity</CardTitle>`,
		`            <CardDescription>Completed tasks over the last 14 days</CardDescription>`,
		`          </CardHeader>`,
		`          <CardContent>`,
		`            <Sparkline data={velocityData}/>`,
		`          </CardContent>`,
		`        </Card>`,
		`        <Card className=\"md:col-span-2\">`,
		`          <CardHeader className=\"pb-2\">`,
		`            <CardTitle className=\"flex items-center gap-2\"><Calendar className=\"h-5 w-5\"/>Project Health</CardTitle>`,
		`            <CardDescription>{selectedProject.name}</CardDescription>`,
		`          </CardHeader>`,
		`          <CardContent>`,
		`            <div className=\"mb-2 flex items-center justify-between text-sm\">`,
		`              <span>Completion</span>`,
		`              <span className=\"font-medium\">{progressPct}%</span>`,
		`            </div>`,
		`            <Progress value={progressPct} className=\"h-2\"/>`,
		`            <div className=\"mt-4 flex flex-wrap gap-2\">`,
		`              {projects.map(p => (`,
		`                <button key={p.id} onClick={()=>dispatch({type:\"select-project\", id:p.id})} className={\`flex items-center gap-2 rounded-xl border px-3 py-2 \${selectedProject.id===p.id?\"ring-2 ring-offset-2\": \"\"}\`} style={{borderColor:p.color}}>`,
		`                  <span className=\"h-2 w-2 rounded-full\" style={{background:p.color}}/>`,
		`                  <span className=\"text-sm\">{p.name}</span>`,
		`                </button>`,
		`              ))}`,
		`            </div>`,
		`          </CardContent>`,
		`        </Card>`,
		`      </div>`,
		``,
		`      <Card className=\"mt-4\">`,
		`        <CardHeader className=\"pb-2\">`,
		`          <div className=\"flex flex-wrap items-center justify-between gap-3\">`,
		`            <div className=\"flex items-center gap-2\">`,
		`              <FolderKanban className=\"h-5 w-5\"/>`,
		`              <CardTitle>Tasks</CardTitle>`,
		`            </div>`,
		`            <div className=\"flex items-center gap-2\">`,
		`              <div className=\"flex items-center gap-2 rounded-xl border px-2 py-1\">`,
		`                <Filter className=\"h-4 w-4 opacity-60\"/>`,
		`                <Input value={query} onChange={(e)=>setQuery(e.target.value)} placeholder=\"Filter by title or tag\" className=\"h-8 border-0 focus-visible:ring-0\"/>`,
		`              </div>`,
		`              <div className=\"hidden items-center gap-2 md:flex\">`,
		`                <span className=\"text-xs opacity-70\">Max estimate</span>`,
		`                <div className=\"w-40\"><Slider value={estimateScale} onValueChange={setEstimateScale} min={1} max={8} step={1}/></div>`,
		`              </div>`,
		`              <Tabs value={tab} onValueChange={setTab} className=\"rounded-xl border\">`,
		`                <TabsList className=\"grid grid-cols-3\">`,
		`                  <TabsTrigger value=\"active\">Active</TabsTrigger>`,
		`                  <TabsTrigger value=\"done\">Done</TabsTrigger>`,
		`                  <TabsTrigger value=\"all\">All</TabsTrigger>`,
		`                </TabsList>`,
		`              </Tabs>`,
		`            </div>`,
		`          </div>`,
		`        </CardHeader>`,
		`        <CardContent>`,
		`          <AnimatePresence initial={false}>`,
		`            <div className=\"space-y-2\">`,
		`              {filtered.map(task => (`,
		`                <TaskRow key={task.id} task={task} project={projectMap[task.projectId]} onToggle={(id)=>dispatch({type:\"toggle-task\", id})} onDelete={(id)=>dispatch({type:\"delete-task\", id})} />`,
		`              ))}`,
		`              {filtered.length===0 && (`,
		`                <div className=\"rounded-xl border p-6 text-center text-sm opacity-70\">No tasks match the current filters</div>`,
		`              )}`,
		`            </div>`,
		`          </AnimatePresence>`,
		`        </CardContent>`,
		`      </Card>`,
		``,
		`      <div className=\"mt-4 grid grid-cols-1 gap-4 md:grid-cols-3\">`,
		`        <Card>`,
		`          <CardHeader className=\"pb-2\">`,
		`            <CardTitle className=\"flex items-center gap-2\"><Clock className=\"h-5 w-5\"/>Focus Timer</CardTitle>`,
		`            <CardDescription>Lightweight session tracking</CardDescription>`,
		`          </CardHeader>`,
		`          <CardContent>`,
		`            <div className=\"flex items-center justify-between\">`,
		`              <Timer running={timerRunning} seconds={seconds} onToggle={()=>setTimerRunning(r=>!r)} />`,
		`              <Button variant=\"ghost\" size=\"icon\" onClick={()=>{setSeconds(0); setTimerRunning(false)}}><X className=\"h-4 w-4\"/></Button>`,
		`            </div>`,
		`            <div className=\"mt-4 flex items-center justify-between\">`,
		`              <div className=\"text-sm opacity-70\">Focus mode</div>`,
		`              <Switch checked={focusMode} onCheckedChange={setFocusMode}/>`,
		`            </div>`,
		`          </CardContent>`,
		`        </Card>`,
		`        <Card>`,
		`          <CardHeader className=\"pb-2\">`,
		`            <CardTitle className=\"flex items-center gap-2\"><Settings className=\"h-5 w-5\"/>Quick Actions</CardTitle>`,
		`            <CardDescription>Perform context operations</CardDescription>`,
		`          </CardHeader>`,
		`          <CardContent>`,
		`            <div className=\"grid grid-cols-2 gap-2\">`,
		`              <Button variant=\"secondary\" className=\"justify-start rounded-xl\" onClick={()=>setBarOpen(true)}><Search className=\"mr-2 h-4 w-4\"/>Open Command</Button>`,
		`              <Button variant=\"secondary\" className=\"justify-start rounded-xl\" onClick={()=>setUploadOpen(true)}><Upload className=\"mr-2 h-4 w-4\"/>Add Task From File</Button>`,
		`              <Button variant=\"secondary\" className=\"justify-start rounded-xl\" onClick={()=>dispatch({type:\"add-task\", task:{ id: crypto.randomUUID(), title: \"Review PR #142\", projectId: state.selectedProject, estimate: 1, done:false, tags:[\"review\"], createdAt: Date.now() }})}><ArrowUpRight className=\"mr-2 h-4 w-4\"/>Quick Add</Button>`,
		`              <Button variant=\"secondary\" className=\"justify-start rounded-xl\" onClick={()=>setQuery(\"\")}><X className=\"mr-2 h-4 w-4\"/>Clear Filters</Button>`,
		`            </div>`,
		`          </CardContent>`,
		`        </Card>`,
		`        <Card>`,
		`          <CardHeader className=\"pb-2\">`,
		`            <CardTitle className=\"flex items-center gap-2\"><BarChart3 className=\"h-5 w-5\"/>Estimates vs Done</CardTitle>`,
		`            <CardDescription>Last 7 tasks</CardDescription>`,
		`          </CardHeader>`,
		`          <CardContent>`,
		`            <ResponsiveContainer width=\"100%\" height={120}>`,
		`              <LineChart data={[...state.tasks].slice(-7).map((t,i)=>( {i, est:t.estimate, done:t.done?1:0} ))} margin={{ top: 8, right: 12, left: 0, bottom: 0 }}>`,
		`                <CartesianGrid strokeOpacity={0.1} vertical={false}/>`,
		`                <XAxis dataKey=\"i\" tickLine={false} axisLine={false}/>`,
		`                <YAxis tickLine={false} axisLine={false}/>`,
		`                <RechartsTooltip/>`,
		`                <Line type=\"monotone\" dataKey=\"est\" stroke=\"currentColor\" strokeWidth={2} dot={false}/>`,
		`                <Line type=\"monotone\" dataKey=\"done\" stroke=\"currentColor\" strokeDasharray=\"4 4\" strokeWidth={2} dot={false}/>`,
		`              </LineChart>`,
		`            </ResponsiveContainer>`,
		`          </CardContent>`,
		`        </Card>`,
		`      </div>`,
		``,
		`      <Dialog open={uploadOpen} onOpenChange={setUploadOpen}>`,
		`        <DialogContent className=\"sm:max-w-md\">`,
		`          <DialogHeader>`,
		`            <DialogTitle>Import Tasks</DialogTitle>`,
		`          </DialogHeader>`,
		`          <div className=\"space-y-3\">`,
		`            <Input ref={fileRef} type=\"file\" accept=\".txt,.md\"/>`,
		`            <div className=\"text-xs opacity-70\">One task per line. Use <code>#tag</code> tokens, and <code>@est=2</code> for estimates.</div>`,
		`            <div className=\"flex justify-end gap-2\">`,
		`              <Button variant=\"ghost\" onClick={()=>setUploadOpen(false)}>Cancel</Button>`,
		`              <Button onClick={()=>{`,
		`                const f = fileRef.current?.files?.[0]`,
		`                if(!f) return`,
		`                const reader = new FileReader()`,
		`                reader.onload = () => {`,
		`                  const lines = String(reader.result).split(/\n+/).map(s=>s.trim()).filter(Boolean)`,
		`                  const tasks = lines.map(line => {`,
		`                    const tags = Array.from(line.matchAll(/#([\\w-]+)/g)).map(m=>m[1])`,
		`                    const est = Number((line.match(/@est=(\\d+)/)?.[1] ?? 2))`,
		`                    const title = line.replace(/#([\\w-]+)/g, \"\").replace(/@est=\\d+/, \"\").trim()`,
		`                    return { id: crypto.randomUUID(), title, projectId: state.selectedProject, estimate: est, done:false, tags, createdAt: Date.now() }`,
		`                  })`,
		`                  tasks.forEach(task => dispatch({type:\"add-task\", task}))`,
		`                  setUploadOpen(false)`,
		`                }`,
		`                reader.readAsText(f)`,
		`              }}>Import</Button>`,
		`            </div>`,
		`          </div>`,
		`        </DialogContent>`,
		`      </Dialog>`,
		``,
		`      <CommandBar open={barOpen} setOpen={setBarOpen} actions={actions}/>`,
		`    </div>`,
		`  )`,
		`}`,
		``,
		`// Optional wrapper if you want to render elsewhere`,
		`export function App(){`,
		`  return <StudioDashboard />`,
		`}`,
		``,
		`// Join helper if you actually need a single string`,
		`export const StudioDashboardString = StudioDashboardLines.join("\n");`,
	],
	rust: [
		"use std::collections::{HashMap, VecDeque};",
		"use std::fmt::{Debug, Formatter};",
		"use std::io::{self, Read};",
		"use std::str::FromStr;",
		"use std::sync::{Arc, Mutex};",
		"use std::sync::mpsc::{self, Sender, Receiver};",
		"use std::thread;",
		"use std::time::{Duration, Instant, SystemTime};",
		"",
		"// ===== Logger =====",
		"#[derive(Clone, Copy, Debug, PartialEq, Eq, PartialOrd, Ord)]",
		"enum Level { Trace, Debug, Info, Warn, Error }",
		"",
		"struct Logger {",
		"    level: Level,",
		"    sink: Arc<Mutex<io::Stdout>>,",
		"}",
		"",
		"impl Logger {",
		"    fn new(level: Level) -> Self {",
		"        Self { level, sink: Arc::new(Mutex::new(io::stdout())) }",
		"    }",
		"",
		"    fn log(&self, level: Level, msg: impl AsRef<str>) {",
		"        if level >= self.level {",
		"            let ts = humantime::format_rfc3339_seconds(SystemTime::now());",
		"            let mut out = self.sink.lock().unwrap();",
		'            let _ = writeln!(out, "[{ts}] {level:?}: {}", msg.as_ref());',
		"        }",
		"    }",
		"",
		"    fn info(&self, msg: impl AsRef<str>) { self.log(Level::Info, msg) }",
		"    fn error(&self, msg: impl AsRef<str>) { self.log(Level::Error, msg) }",
		"    fn debug(&self, msg: impl AsRef<str>) { self.log(Level::Debug, msg) }",
		"}",
		"",
		"// ===== Exponential Backoff =====",
		"#[derive(Clone, Debug)]",
		"struct Backoff {",
		"    base: Duration,",
		"    factor: f64,",
		"    max: Duration,",
		"    jitter: f64,",
		"}",
		"",
		"impl Backoff {",
		"    fn new(base: Duration, factor: f64, max: Duration, jitter: f64) -> Self {",
		"        Self { base, factor, max, jitter }",
		"    }",
		"",
		"    fn duration_for(&self, attempt: u32) -> Duration {",
		"        let pow = self.factor.powi(attempt as i32);",
		"        let mut ms = (self.base.as_millis() as f64 * pow).min(self.max.as_millis() as f64);",
		"        if self.jitter > 0.0 {",
		"            let jitter_ms = (rand_seeded() * self.jitter) * ms;",
		"            ms += jitter_ms;",
		"        }",
		"        Duration::from_millis(ms.max(0.0) as u64)",
		"    }",
		"}",
		"",
		"// A tiny, deterministic PRNG for jitter (no external deps required)",
		"fn rand_seeded() -> f64 {",
		"    use std::hash::{Hash, Hasher};",
		"    use std::time::{SystemTime, UNIX_EPOCH};",
		"    let now = SystemTime::now().duration_since(UNIX_EPOCH).unwrap().as_nanos();",
		'    let tid = thread::current().name().unwrap_or("");',
		"    let mut s = std::collections::hash_map::DefaultHasher::new();",
		"    now.hash(&mut s);",
		"    tid.hash(&mut s);",
		"    let v = s.finish();",
		"    // map to (0,1)",
		"    ((v % 10_000) as f64 + 1.0) / 10_001.0",
		"}",
		"",
		"// ===== Token Bucket Rate Limiter =====",
		"#[derive(Clone, Debug)]",
		"struct TokenBucket {",
		"    capacity: f64,",
		"    tokens: f64,",
		"    refill_per_sec: f64,",
		"    last: Instant,",
		"}",
		"",
		"impl TokenBucket {",
		"    fn new(capacity: f64, refill_per_sec: f64) -> Self {",
		"        Self { capacity, tokens: capacity, refill_per_sec, last: Instant::now() }",
		"    }",
		"",
		"    fn allow(&mut self, cost: f64) -> bool {",
		"        self.refill();",
		"        if self.tokens >= cost {",
		"            self.tokens -= cost;",
		"            true",
		"        } else {",
		"            false",
		"        }",
		"    }",
		"",
		"    fn until_next(&mut self, cost: f64) -> Duration {",
		"        self.refill();",
		"        if self.tokens >= cost { return Duration::from_secs(0); }",
		"        let needed = cost - self.tokens;",
		"        let secs = needed / self.refill_per_sec;",
		"        Duration::from_secs_f64(secs.max(0.0))",
		"    }",
		"",
		"    fn refill(&mut self) {",
		"        let now = Instant::now();",
		"        let delta = now.duration_since(self.last).as_secs_f64();",
		"        self.tokens = (self.tokens + delta * self.refill_per_sec).min(self.capacity);",
		"        self.last = now;",
		"    }",
		"}",
		"",
		"// ===== Simple LRU Cache (move-to-front; O(n) update) =====",
		"#[derive(Clone)]",
		"struct LruCache<K, V> where K: Eq + Clone + Debug {",
		"    order: VecDeque<K>,",
		"    map: HashMap<K, V>,",
		"    cap: usize,",
		"}",
		"",
		"impl<K, V> LruCache<K, V> where K: Eq + Clone + Debug {",
		"    fn new(cap: usize) -> Self {",
		"        Self { order: VecDeque::new(), map: HashMap::new(), cap }",
		"    }",
		"",
		"    fn get(&mut self, k: &K) -> Option<&V> {",
		"        if self.map.contains_key(k) {",
		"            self.touch(k.clone());",
		"        }",
		"        self.map.get(k)",
		"    }",
		"",
		"    fn insert(&mut self, k: K, v: V) {",
		"        if self.map.contains_key(&k) {",
		"            self.map.insert(k.clone(), v);",
		"            self.touch(k);",
		"            return;",
		"        }",
		"        if self.order.len() == self.cap {",
		"            if let Some(old) = self.order.pop_back() {",
		"                self.map.remove(&old);",
		"            }",
		"        }",
		"        self.order.push_front(k.clone());",
		"        self.map.insert(k, v);",
		"    }",
		"",
		"    fn touch(&mut self, k: K) {",
		"        let mut idx = None;",
		"        for (i, key) in self.order.iter().enumerate() {",
		"            if key == &k { idx = Some(i); break; }",
		"        }",
		"        if let Some(i) = idx { self.order.remove(i); }",
		"        self.order.push_front(k);",
		"    }",
		"}",
		"",
		"impl<K: Debug, V: Debug> Debug for LruCache<K, V> where K: Eq + Clone {",
		"    fn fmt(&self, f: &mut Formatter<'_>) -> std::fmt::Result {",
		'        f.debug_struct("LruCache")',
		'            .field("cap", &self.cap)',
		'            .field("len", &self.map.len())',
		"            .finish()",
		"    }",
		"}",
		"",
		"// ===== Online Statistics (Welford) =====",
		"#[derive(Default, Clone, Debug)]",
		"struct RunningStats {",
		"    n: u64,",
		"    mean: f64,",
		"    m2: f64,",
		"}",
		"",
		"impl RunningStats {",
		"    fn update(&mut self, x: f64) {",
		"        self.n += 1;",
		"        let delta = x - self.mean;",
		"        self.mean += delta / self.n as f64;",
		"        let delta2 = x - self.mean;",
		"        self.m2 += delta * delta2;",
		"    }",
		"",
		"    fn mean(&self) -> f64 { self.mean }",
		"    fn var(&self) -> f64 { if self.n > 1 { self.m2 / (self.n - 1) as f64 } else { 0.0 } }",
		"    fn stddev(&self) -> f64 { self.var().sqrt() }",
		"    fn count(&self) -> u64 { self.n }",
		"}",
		"",
		"// ===== INI Parser =====",
		"#[derive(Debug, Clone)]",
		"struct Ini { data: HashMap<String, HashMap<String, String>> }",
		"",
		"impl Ini {",
		"    fn from_str(s: &str) -> Self {",
		'        let mut current = String::from("");',
		"        let mut data: HashMap<String, HashMap<String, String>> = HashMap::new();",
		"        for line in s.lines() {",
		"            let line = line.trim();",
		"            if line.is_empty() || line.starts_with('#') || line.starts_with(';') { continue; }",
		"            if line.starts_with('[') && line.ends_with(']') {",
		"                current = line[1..line.len()-1].trim().to_string();",
		"                data.entry(current.clone()).or_default();",
		"            } else if let Some(eq) = line.find('=') {",
		"                let (k, v) = line.split_at(eq);",
		"                let key = k.trim().to_string();",
		"                let val = v[1..].trim().to_string();",
		"                data.entry(current.clone()).or_default().insert(key, val);",
		"            }",
		"        }",
		"        Self { data }",
		"    }",
		"",
		"    fn get(&self, section: &str, key: &str) -> Option<&str> {",
		"        self.data.get(section).and_then(|m| m.get(key)).map(|s| s.as_str())",
		"    }",
		"}",
		"",
		"// ===== Thread Pool & Scheduler =====",
		"struct Job { id: u64, name: String, payload: Box<dyn FnOnce() + Send + 'static> }",
		"",
		"struct ThreadPool {",
		"    tx: Sender<Option<Job>>,",
		"    join: Vec<thread::JoinHandle<()>>,",
		"}",
		"",
		"impl ThreadPool {",
		"    fn new(size: usize, log: Logger) -> Self {",
		"        let (tx, rx): (Sender<Option<Job>>, Receiver<Option<Job>>) = mpsc::channel();",
		"        let rx = Arc::new(Mutex::new(rx));",
		"        let mut join = Vec::with_capacity(size);",
		"        for i in 0..size {",
		"            let rx = rx.clone();",
		"            let log = log.clone();",
		'            let name = format!("worker-{i}");',
		"            let handle = thread::Builder::new().name(name.clone()).spawn(move || {",
		"                loop {",
		"                    let job_opt = rx.lock().unwrap().recv().unwrap();",
		"                    match job_opt {",
		"                        Some(job) => {",
		'                            log.debug(format!("{name} running job {} ({})", job.id, job.name));',
		"                            (job.payload)();",
		"                        }",
		"                        None => {",
		'                            log.debug(format!("{name} shutting down"));',
		"                            break;",
		"                        }",
		"                    }",
		"                }",
		'            }).expect("spawn worker");',
		"            join.push(handle);",
		"        }",
		"        Self { tx, join }",
		"    }",
		"",
		"    fn submit<F: FnOnce() + Send + 'static>(&self, id: u64, name: impl Into<String>, f: F) {",
		"        let _ = self.tx.send(Some(Job { id, name: name.into(), payload: Box::new(f) }));",
		"    }",
		"}",
		"",
		"impl Drop for ThreadPool {",
		"    fn drop(&mut self) {",
		"        for _ in &self.join { let _ = self.tx.send(None); }",
		"        for h in self.join.drain(..) { let _ = h.join(); }",
		"    }",
		"}",
		"",
		"// ===== Example Workload =====",
		"fn is_prime(n: u64) -> bool {",
		"    if n < 2 { return false; }",
		"    if n % 2 == 0 { return n == 2; }",
		"    let mut d = 3u64;",
		"    while d * d <= n { if n % d == 0 { return false; } d += 2; }",
		"    true",
		"}",
		"",
		"fn fib(n: u64) -> u64 {",
		"    let (mut a, mut b) = (0u64, 1u64);",
		"    for _ in 0..n { let c = a + b; a = b; b = c; }",
		"    a",
		"}",
		"",
		"// ===== Typed value parsing =====",
		"#[derive(Debug, Clone)]",
		"struct DurationSecs(pub Duration);",
		"impl FromStr for DurationSecs {",
		"    type Err = String;",
		"    fn from_str(s: &str) -> Result<Self, Self::Err> {",
		"        let s = s.trim();",
		"        if let Some(stripped) = s.strip_suffix('s') {",
		"            let v: f64 = stripped.parse().map_err(|e| e.to_string())?;",
		"            Ok(Self(Duration::from_secs_f64(v)))",
		"        } else if let Some(stripped) = s.strip_suffix('m') {",
		"            let v: f64 = stripped.parse().map_err(|e| e.to_string())?;",
		"            Ok(Self(Duration::from_secs_f64(v * 60.0)))",
		"        } else if let Some(stripped) = s.strip_suffix('h') {",
		"            let v: f64 = stripped.parse().map_err(|e| e.to_string())?;",
		"            Ok(Self(Duration::from_secs_f64(v * 3600.0)))",
		"        } else {",
		"            let v: f64 = s.parse().map_err(|e| e.to_string())?;",
		"            Ok(Self(Duration::from_secs_f64(v)))",
		"        }",
		"    }",
		"}",
		"",
		"// ===== Main =====",
		"fn main() {",
		"    let logger = Logger::new(Level::Info);",
		"",
		"    // Read optional INI config from stdin (piped) or fall back to defaults",
		"    let mut buf = String::new();",
		"    if io::stdin().read_to_string(&mut buf).unwrap_or(0) == 0 {",
		'        buf = r#"',
		"        [scheduler]",
		"        threads = 4",
		"        queue_rate = 10.0",
		"        [work]",
		"        jobs = 25",
		"        fib_n = 36",
		"        prime_from = 2_000_000",
		"        prime_count = 300",
		"        backoff_base = 50ms",
		'        "#.to_string();',
		"    }",
		"",
		"    let ini = Ini::from_str(&buf);",
		'    let threads: usize = ini.get("scheduler", "threads").and_then(|s| s.parse().ok()).unwrap_or(4);',
		'    let rate: f64 = ini.get("scheduler", "queue_rate").and_then(|s| s.parse().ok()).unwrap_or(15.0);',
		"",
		'    let jobs: u64 = ini.get("work", "jobs").and_then(|s| s.parse().ok()).unwrap_or(20);',
		'    let fib_n: u64 = ini.get("work", "fib_n").and_then(|s| s.parse().ok()).unwrap_or(34);',
		'    let prime_from: u64 = ini.get("work", "prime_from").and_then(|s| s.replace(\'_\', "").parse().ok()).unwrap_or(1_500_000);',
		'    let prime_count: u64 = ini.get("work", "prime_count").and_then(|s| s.parse().ok()).unwrap_or(200);',
		"",
		"    let pool = ThreadPool::new(threads, Logger::new(Level::Debug));",
		"    let mut limiter = TokenBucket::new(rate, rate); // average N enqueues per second",
		"",
		"    let mut backoff = Backoff::new(Duration::from_millis(25), 2.0, Duration::from_millis(400), 0.15);",
		"",
		"    let mut cache: LruCache<u64, u64> = LruCache::new(64);",
		"    let stats = Arc::new(Mutex::new(RunningStats::default()));",
		"",
		'    logger.info(format!("threads={threads} rate={rate} jobs={jobs} fib_n={fib_n} primes@{prime_from}+{prime_count}"));',
		"",
		"    let start = Instant::now();",
		"    let mut submitted = 0u64;",
		"    let mut next_prime = prime_from;",
		"    let mut found_primes = 0u64;",
		"",
		"    while submitted < jobs {",
		"        if limiter.allow(1.0) {",
		"            let id = submitted + 1;",
		"            let sstats = stats.clone();",
		"            let mut cbackoff = backoff.clone();",
		"            let mut local_cache = cache.clone();",
		'            let name = if id % 2 == 0 { format!("fib({fib_n})") } else { format!("prime_search") };',
		"            pool.submit(id, name, move || {",
		"                let t0 = Instant::now();",
		'                // Occasionally "fail" a unit of work to exercise backoff',
		"                let mut attempt = 0u32;",
		"                loop {",
		"                    attempt += 1;",
		"                    let ok = (rand_seeded() > 0.1) || attempt > 3;",
		"                    if ok { break; }",
		"                    thread::sleep(cbackoff.duration_for(attempt));",
		"                }",
		"",
		"                // Do some work",
		"                let res = if id % 2 == 0 {",
		"                    if let Some(v) = local_cache.get(&fib_n).cloned() { v } else { let v = fib(fib_n); local_cache.insert(fib_n, v); v }",
		"                } else {",
		'                    // find one prime bigger than "id" threshold to keep it varied',
		"                    let mut x = 10_000 + id * 13;",
		"                    while !is_prime(x) { x += 1; }",
		"                    x",
		"                };",
		"",
		"                let dt = t0.elapsed().as_secs_f64();",
		"                let mut s = sstats.lock().unwrap();",
		"                s.update(dt);",
		"            });",
		"            submitted += 1;",
		"        } else {",
		"            let sleep_for = limiter.until_next(1.0);",
		"            thread::sleep(sleep_for);",
		"        }",
		"    }",
		"",
		"    drop(pool); // join",
		"",
		"    // Extra prime work in main thread to exercise deterministic logic",
		"    while found_primes < prime_count {",
		"        if is_prime(next_prime) { found_primes += 1; }",
		"        next_prime += 1;",
		"    }",
		"",
		"    let total = start.elapsed();",
		"    let s = stats.lock().unwrap().clone();",
		"    logger.info(format!(",
		'        "done in {:.2?} | tasks: {} | mean: {:.3}s stddev: {:.3}s count: {} | last prime tested: {}",',
		"        total, jobs, s.mean(), s.stddev(), s.count(), next_prime - 1",
		"    ));",
		"}",
		"",
		"// ===== Minimal dependency: humantime (feature gate) =====",
		"// Add to Cargo.toml if you want timestamps printed as RFC3339:",
		"// [dependencies]",
		'// humantime = "2"',
	],
	go: [
		"package main",
		"",
		"import (",
		'    "context"',
		'    "crypto/rand"',
		'    "encoding/hex"',
		'    "encoding/json"',
		'    "errors"',
		'    "fmt"',
		'    "log"',
		'    "math"',
		'    "net/http"',
		'    "os"',
		'    "os/signal"',
		'    "runtime"',
		'    "sort"',
		'    "strconv"',
		'    "strings"',
		'    "sync"',
		'    "sync/atomic"',
		'    "text/template"',
		'    "time"',
		")",
		"",
		"// Config holds runtime configuration sourced from environment variables.",
		"// All fields have sensible defaults so the service works out of the box.",
		"type Config struct {",
		'    Addr    string    // HTTP bind address, e.g. ":8080"',
		"    Workers    int    // number of background workers",
		"    QueueCapacity     int    // buffered channel capacity",
		"    ShutdownGrace     time.Duration // graceful shutdown timeout",
		"    RequestTimeout time.Duration // per-request timeout",
		"}",
		"",
		"func loadConfig() Config {",
		"    cfg := Config{",
		'    Addr:    getEnv("APP_ADDR", ":8080"),',
		'    Workers:    mustAtoi(getEnv("APP_WORKERS", strconv.Itoa(max(2, runtime.NumCPU()-1)))),',
		'    QueueCapacity:    mustAtoi(getEnv("APP_QUEUE_CAP", "1024")),',
		'    ShutdownGrace:    mustParseDuration(getEnv("APP_SHUTDOWN_GRACE", "10s")),',
		'    RequestTimeout: mustParseDuration(getEnv("APP_REQUEST_TIMEOUT", "3s")),',
		"    }",
		"    if cfg.Workers < 1 {",
		"    cfg.Workers = 1",
		"    }",
		"    if cfg.QueueCapacity < 1 {",
		"    cfg.QueueCapacity = 64",
		"    }",
		"    return cfg",
		"}",
		"",
		"func getEnv(key, def string) string {",
		"    v := os.Getenv(key)",
		'    if v == "" {',
		"    return def",
		"    }",
		"    return v",
		"}",
		"",
		"func mustAtoi(s string) int {",
		"    i, err := strconv.Atoi(s)",
		"    if err != nil {",
		"    return 0",
		"    }",
		"    return i",
		"}",
		"",
		"func mustParseDuration(s string) time.Duration {",
		"    d, err := time.ParseDuration(s)",
		"    if err != nil {",
		"    return 0",
		"    }",
		"    return d",
		"}",
		"",
		"// Task represents a unit of work.",
		"type Task struct {",
		'    ID    string    `json:"id"`',
		'    Type    string    `json:"type"`    // e.g. "email", "reindex", "report"',
		'    Payload    map[string]string `json:"payload"`    // arbitrary kv',
		'    CreatedAt time.Time     `json:"createdAt"`',
		'    Status     string    `json:"status"`    // queued, running, done, failed',
		'    Result     string    `json:"result"`    // human-readable summary',
		'    LatencyMs int64    `json:"latencyMs"` // from queue to completion',
		"}",
		"",
		"// MemoryStore is a concurrency-safe task registry.",
		"type MemoryStore struct {",
		"    mu    sync.RWMutex",
		"    tasks map[string]*Task",
		"}",
		"",
		"func NewMemoryStore() *MemoryStore { return &MemoryStore{tasks: make(map[string]*Task)} }",
		"",
		"func (s *MemoryStore) Put(t *Task) {",
		"    s.mu.Lock()",
		"    s.tasks[t.ID] = t",
		"    s.mu.Unlock()",
		"}",
		"",
		"func (s *MemoryStore) Get(id string) (*Task, bool) {",
		"    s.mu.RLock()",
		"    t, ok := s.tasks[id]",
		"    s.mu.RUnlock()",
		"    return t, ok",
		"}",
		"",
		"func (s *MemoryStore) List(limit int) []*Task {",
		"    s.mu.RLock()",
		"    arr := make([]*Task, 0, len(s.tasks))",
		"    for _, t := range s.tasks {",
		"    arr = append(arr, t)",
		"    }",
		"    s.mu.RUnlock()",
		"    sort.Slice(arr, func(i, j int) bool { return arr[i].CreatedAt.After(arr[j].CreatedAt) })",
		"    if limit > 0 && len(arr) > limit {",
		"    return arr[:limit]",
		"    }",
		"    return arr",
		"}",
		"",
		"// WorkItem is what the workers actually process.",
		"type WorkItem struct {",
		"    TaskID string",
		"}",
		"",
		"// Metrics collects counters and moving-window latencies.",
		"type Metrics struct {",
		"    Enqueued     atomic.Int64",
		"    Started     atomic.Int64",
		"    Completed  atomic.Int64",
		"    Failed      atomic.Int64",
		"    QueueDepth atomic.Int64",
		"    LastErr     atomic.Value // string",
		"",
		"    mu          sync.Mutex",
		"    latency  []int64 // ring buffer of recent latency ms",
		"    capacity int",
		"    idx          int",
		"}",
		"",
		"func NewMetrics(cap int) *Metrics { return &Metrics{capacity: max(32, cap)} }",
		"",
		"func (m *Metrics) RecordLatency(ms int64) {",
		"    m.mu.Lock()",
		"    if m.latency == nil {",
		"    m.latency = make([]int64, m.capacity)",
		"    }",
		"    m.latency[m.idx%m.capacity] = ms",
		"    m.idx++",
		"    m.mu.Unlock()",
		"}",
		"",
		"func (m *Metrics) Snapshot() map[string]any {",
		"    m.mu.Lock()",
		"    lat := append([]int64(nil), m.latency...)",
		"    count := min(m.idx, m.capacity)",
		"    m.mu.Unlock()",
		"",
		"    var mean, p95, p99 float64",
		"    if count > 0 {",
		"    sorted := append([]int64(nil), lat[:count]...)",
		"    sort.Slice(sorted, func(i, j int) bool { return sorted[i] < sorted[j] })",
		"    var sum int64",
		"    for _, v := range sorted {",
		"    sum += v",
		"    }",
		"    mean = float64(sum) / float64(count)",
		"    p95 = float64(sorted[int(math.Ceil(0.95*float64(count)))-1])",
		"    p99 = float64(sorted[int(math.Ceil(0.99*float64(count)))-1])",
		"    }",
		"    lastErr, _ := m.LastErr.Load().(string)",
		"    return map[string]any{",
		'    "enqueued":   m.Enqueued.Load(),',
		'    "started":    m.Started.Load(),',
		'    "completed":  m.Completed.Load(),',
		'    "failed":     m.Failed.Load(),',
		'    "queueDepth": m.QueueDepth.Load(),',
		'    "latencyMs": map[string]float64{',
		'    "mean": mean,',
		'    "p95":  p95,',
		'    "p99":  p99,',
		"    },",
		'    "lastError": lastErr,',
		"    }",
		"}",
		"",
		"// Dispatcher coordinates enqueueing and worker consumption.",
		"type Dispatcher struct {",
		"    cfg        Config",
		"    store      *MemoryStore",
		"    metrics *Metrics",
		"    queue      chan WorkItem",
		"    wg         sync.WaitGroup",
		"}",
		"",
		"func NewDispatcher(cfg Config, store *MemoryStore, metrics *Metrics) *Dispatcher {",
		"    return &Dispatcher{",
		"    cfg:        cfg,",
		"    store:      store,",
		"    metrics: metrics,",
		"    queue:      make(chan WorkItem, cfg.QueueCapacity),",
		"    }",
		"}",
		"",
		"func (d *Dispatcher) Start(ctx context.Context) {",
		"    for i := 0; i < d.cfg.Workers; i++ {",
		"    d.wg.Add(1)",
		"    go d.worker(ctx, i)",
		"    }",
		"}",
		"",
		"func (d *Dispatcher) Stop() {",
		"    close(d.queue)",
		"    d.wg.Wait()",
		"}",
		"",
		"func (d *Dispatcher) Enqueue(t *Task) error {",
		"    select {",
		"    case d.queue <- WorkItem{TaskID: t.ID}:",
		"    d.metrics.Enqueued.Add(1)",
		"    d.metrics.QueueDepth.Add(1)",
		"    return nil",
		"    default:",
		'    return errors.New("queue is full")',
		"    }",
		"}",
		"",
		"func (d *Dispatcher) worker(ctx context.Context, id int) {",
		"    defer d.wg.Done()",
		"    for item := range d.queue {",
		"    d.metrics.QueueDepth.Add(-1)",
		"    d.metrics.Started.Add(1)",
		"    start := time.Now()",
		"",
		"    t, ok := d.store.Get(item.TaskID)",
		"    if !ok {",
		"    d.metrics.Failed.Add(1)",
		'    d.metrics.LastErr.Store("missing task: " + item.TaskID)',
		"    continue",
		"    }",
		'    t.Status = "running"',
		"",
		"    // Simulate realistic processing branches based on task type.",
		"    var err error",
		"    switch strings.ToLower(t.Type) {",
		'    case "email":',
		"    err = processEmail(t)",
		'    case "reindex":',
		"    err = processReindex(t)",
		'    case "report":',
		"    err = processReport(t)",
		"    default:",
		"    err = processGeneric(t)",
		"    }",
		"",
		"    elapsed := time.Since(start).Milliseconds()",
		"    d.metrics.RecordLatency(elapsed)",
		"    t.LatencyMs = elapsed",
		"    if err != nil {",
		'    t.Status = "failed"',
		"    t.Result = err.Error()",
		"    d.metrics.Failed.Add(1)",
		"    d.metrics.LastErr.Store(err.Error())",
		"    } else {",
		'    t.Status = "done"',
		"    d.metrics.Completed.Add(1)",
		"    }",
		"    }",
		"}",
		"",
		"// Simulated processors that look realistic.",
		"func processEmail(t *Task) error {",
		'    recipient := t.Payload["to"]',
		'    if recipient == "" {',
		'    return errors.New("missing recipient")',
		"    }",
		'    subject := t.Payload["subject"]',
		'    body := t.Payload["body"]',
		"    // Simulate latency and a basic validation",
		"    time.Sleep(40*time.Millisecond + time.Duration(len(body)%100)*time.Millisecond)",
		'    if !strings.Contains(recipient, "@") {',
		'    return fmt.Errorf("invalid email: %s", recipient)',
		"    }",
		'    t.Result = fmt.Sprintf("sent %d bytes to %s with subject %q", len(body), recipient, subject)',
		"    return nil",
		"}",
		"",
		"func processReindex(t *Task) error {",
		'    index := t.Payload["index"]',
		'    if index == "" {',
		'    index = "default"',
		"    }",
		"    shards := 3",
		'    if v := t.Payload["shards"]; v != "" {',
		"    if n, err := strconv.Atoi(v); err == nil && n > 0 {",
		"    shards = n",
		"    }",
		"    }",
		"    for i := 0; i < shards; i++ {",
		"    time.Sleep(35 * time.Millisecond)",
		"    }",
		'    t.Result = fmt.Sprintf("reindexed %s with %d shards", index, shards)',
		"    return nil",
		"}",
		"",
		"func processReport(t *Task) error {",
		'    period := t.Payload["period"]',
		'    if period == "" {',
		'    period = "7d"',
		"    }",
		"    // fake aggregation complexity proportional to period length",
		"    n := len(period)",
		"    var sum int",
		"    for i := 0; i < 2000+(n*250); i++ {",
		"    sum += i % 97",
		"    }",
		"    time.Sleep(50 * time.Millisecond)",
		'    t.Result = fmt.Sprintf("report %s ready (score=%d)", period, sum%1000)',
		"    return nil",
		"}",
		"",
		"func processGeneric(t *Task) error {",
		"    // perform a deterministic pseudo-workload based on payload keys",
		"    keys := make([]string, 0, len(t.Payload))",
		"    for k := range t.Payload {",
		"    keys = append(keys, k)",
		"    }",
		"    sort.Strings(keys)",
		"    var acc int",
		"    for _, k := range keys {",
		"    v := t.Payload[k]",
		"    acc += len(k) * (1 + len(v))",
		"    if len(v)%7 == 0 {",
		"    time.Sleep(12 * time.Millisecond)",
		"    }",
		"    }",
		'    t.Result = fmt.Sprintf("processed %d fields", len(keys))',
		"    return nil",
		"}",
		"",
		"// HTTP and presentation layer",
		'var homeTPL = template.Must(template.New("home").Parse(`<!doctype html>',
		"<html>",
		"<head>",
		'    <meta charset="utf-8" />',
		'    <meta name="viewport" content="width=device-width, initial-scale=1" />',
		"    <title>Task Queue</title>",
		"    <style>",
		"    body{font-family:system-ui, -apple-system, Segoe UI, Roboto, Ubuntu, Cantarell, Noto Sans, sans-serif; margin:2rem;}",
		"    code{background:#f6f8fa;padding:.15rem .3rem;border-radius:.25rem}",
		"    .card{border:1px solid #e5e7eb;border-radius:.75rem;padding:1rem;margin:.5rem 0}",
		"    .grid{display:grid;grid-template-columns:repeat(auto-fit,minmax(280px,1fr));gap:1rem}",
		"    .small{color:#6b7280;font-size:.9rem}",
		"    .badge{display:inline-block;padding:.15rem .45rem;border-radius:.5rem;background:#eef2ff}",
		"    </style>",
		"</head>",
		"<body>",
		"    <h1>Task Queue</h1>",
		'    <p class="small">POST <code>/enqueue</code> with JSON; GET <code>/stats</code>, <code>/tasks</code>, <code>/tasks/{id}</code>, <code>/health</code>.</p>',
		'    <div class="grid">',
		'    <div class="card">',
		"    <h3>Quick Enqueue</h3>",
		"    <form method=\"post\" action=\"/enqueue\" onsubmit=\"event.preventDefault();fetch('/enqueue',{method:'POST',headers:{'content-type':'application/json'},body:JSON.stringify({type:document.getElementById('type').value,payload:{to:'you@example.com',subject:'Hello',body:'World'}})}).then(r=>r.json()).then(x=>location.href='/tasks/'+x.id)\">",
		"    <label>Type",
		'    <select id="type">',
		"    <option>email</option>",
		"    <option>reindex</option>",
		"    <option>report</option>",
		"    <option>generic</option>",
		"    </select>",
		"    </label>",
		'    <button type="submit">Enqueue</button>',
		"    </form>",
		"    </div>",
		'    <div class="card">',
		"    <h3>Metrics</h3>",
		'    <pre id="m">loadingâ€¦</pre>',
		"    </div>",
		"    </div>",
		"    <script>",
		"    async function refresh(){",
		"    let r = await fetch('/stats');",
		"    document.getElementById('m').textContent = JSON.stringify(await r.json(), null, 2);",
		"    }",
		"    setInterval(refresh, 1500);",
		"    refresh();",
		"    </script>",
		"</body>",
		"</html>`))",
		"",
		"// App wires everything together.",
		"type App struct {",
		"    cfg        Config",
		"    dispatcher *Dispatcher",
		"    store      *MemoryStore",
		"    metrics    *Metrics",
		"}",
		"",
		"func NewApp(cfg Config) *App {",
		"    store := NewMemoryStore()",
		"    metrics := NewMetrics(256)",
		"    d := NewDispatcher(cfg, store, metrics)",
		"    return &App{cfg: cfg, dispatcher: d, store: store, metrics: metrics}",
		"}",
		"",
		"func (a *App) routes() http.Handler {",
		"    mux := http.NewServeMux()",
		'    mux.HandleFunc("/", a.handleHome)',
		'    mux.HandleFunc("/health", a.handleHealth)',
		'    mux.HandleFunc("/enqueue", a.withTimeout(a.handleEnqueue))',
		'    mux.HandleFunc("/stats", a.handleStats)',
		'    mux.HandleFunc("/tasks", a.handleTasks)',
		'    mux.HandleFunc("/tasks/", a.handleTaskByID)',
		"    return logging(mux)",
		"}",
		"",
		"func (a *App) handleHome(w http.ResponseWriter, r *http.Request) {",
		"    _ = homeTPL.Execute(w, nil)",
		"}",
		"",
		"func (a *App) handleHealth(w http.ResponseWriter, r *http.Request) {",
		'    w.Header().Set("content-type", "application/json")',
		'    json.NewEncoder(w).Encode(map[string]string{"status": "ok"})',
		"}",
		"",
		"func (a *App) handleStats(w http.ResponseWriter, r *http.Request) {",
		'    w.Header().Set("content-type", "application/json")',
		"    json.NewEncoder(w).Encode(a.metrics.Snapshot())",
		"}",
		"",
		"func (a *App) handleTasks(w http.ResponseWriter, r *http.Request) {",
		'    w.Header().Set("content-type", "application/json")',
		"    json.NewEncoder(w).Encode(a.store.List(200))",
		"}",
		"",
		"func (a *App) handleTaskByID(w http.ResponseWriter, r *http.Request) {",
		'    id := strings.TrimPrefix(r.URL.Path, "/tasks/")',
		'    if id == "" {',
		"    http.NotFound(w, r)",
		"    return",
		"    }",
		"    if t, ok := a.store.Get(id); ok {",
		'    w.Header().Set("content-type", "application/json")',
		"    json.NewEncoder(w).Encode(t)",
		"    return",
		"    }",
		"    http.NotFound(w, r)",
		"}",
		"",
		"func (a *App) handleEnqueue(w http.ResponseWriter, r *http.Request) {",
		"    if r.Method != http.MethodPost {",
		'    http.Error(w, "method not allowed", http.StatusMethodNotAllowed)',
		"    return",
		"    }",
		"    var in struct {",
		'    Type       string            `json:"type"`',
		'    Payload map[string]string `json:"payload"`',
		"    }",
		"    if err := json.NewDecoder(http.MaxBytesReader(w, r.Body, 1<<20)).Decode(&in); err != nil {",
		'    http.Error(w, "bad request", http.StatusBadRequest)',
		"    return",
		"    }",
		'    if in.Type == "" {',
		'    in.Type = "generic"',
		"    }",
		"    t := &Task{",
		"    ID:    newID()",
		"    Type:       in.Type,",
		"    Payload:   in.Payload,",
		"    CreatedAt: time.Now(),",
		'    Status:     "queued",',
		"    }",
		"    a.store.Put(t)",
		"    if err := a.dispatcher.Enqueue(t); err != nil {",
		"    http.Error(w, err.Error(), http.StatusServiceUnavailable)",
		"    return",
		"    }",
		'    w.Header().Set("content-type", "application/json")',
		"    w.WriteHeader(http.StatusAccepted)",
		'    json.NewEncoder(w).Encode(map[string]string{"id": t.ID})',
		"}",
		"",
		"func (a *App) withTimeout(next http.HandlerFunc) http.HandlerFunc {",
		"    return func(w http.ResponseWriter, r *http.Request) {",
		"    ctx, cancel := context.WithTimeout(r.Context(), a.cfg.RequestTimeout)",
		"    defer cancel()",
		"    nr := r.Clone(ctx)",
		"    done := make(chan struct{})",
		"    go func() { next(w, nr); close(done) }()",
		"    select {",
		"    case <-done:",
		"    return",
		"    case <-ctx.Done():",
		'    http.Error(w, "deadline exceeded", http.StatusGatewayTimeout)',
		"    }",
		"    }",
		"}",
		"",
		"func logging(next http.Handler) http.Handler {",
		"    return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {",
		"    start := time.Now()",
		"    next.ServeHTTP(w, r)",
		'    log.Printf("%s %s %s", r.Method, r.URL.Path, time.Since(start))',
		"    })",
		"}",
		"",
		"func newID() string {",
		"    var b [16]byte",
		"    _, _ = rand.Read(b[:])",
		"    return hex.EncodeToString(b[:])",
		"}",
		"",
		"func main() {",
		"    cfg := loadConfig()",
		"    app := NewApp(cfg)",
		"",
		"    ctx, cancel := signal.NotifyContext(context.Background(), os.Interrupt)",
		"    defer cancel()",
		"",
		"    app.dispatcher.Start(ctx)",
		"",
		"    srv := &http.Server{Addr: cfg.Addr, Handler: app.routes()}",
		"",
		"    go func() {",
		'    log.Printf("listening on %s (workers=%d, cap=%d)", cfg.Addr, cfg.Workers, cfg.QueueCapacity)',
		"    if err := srv.ListenAndServe(); err != nil && !errors.Is(err, http.ErrServerClosed) {",
		'    log.Fatalf("server error: %v", err)',
		"    }",
		"    }()",
		"",
		"    <-ctx.Done()",
		'    log.Println("shutting downâ€¦")',
		"",
		"    shCtx, shCancel := context.WithTimeout(context.Background(), cfg.ShutdownGrace)",
		"    defer shCancel()",
		"    _ = srv.Shutdown(shCtx)",
		"    app.dispatcher.Stop()",
		'    log.Println("bye")',
		"}",
		"",
		"// tiny helpers",
		"func min(a, b int) int { if a < b { return a }; return b }",
		"func max(a, b int) int { if a > b { return a }; return b }",
	],
	python: [
		"#!/usr/bin/env python3",
		"import argparse",
		"import csv",
		"import http.server",
		"import json",
		"import os",
		"import queue",
		"import random",
		"import sqlite3",
		"import socketserver",
		"import sqlite3",
		"import threading",
		"import time",
		"import traceback",
		"from contextlib import closing",
		"from dataclasses import dataclass, asdict",
		"from datetime import datetime, timedelta",
		"from pathlib import Path",
		"from typing import Any, Dict, Iterable, List, Optional, Tuple, Callable",
		"",
		"# --- configuration and simple persistence ---",
		"@dataclass",
		"class Config:",
		'    db_path: str = "toolbox.db"',
		'    cache_dir: str = ".cache"',
		"    http_port: int = 8000",
		"    max_tasks: int = 8",
		"",
		"    def ensure(self):",
		"        os.makedirs(self.cache_dir, exist_ok=True)",
		"        conn = sqlite3.connect(self.db_path)",
		"        with conn:",
		'            conn.execute("""',
		"            CREATE TABLE IF NOT EXISTS records (",
		"                id INTEGER PRIMARY KEY AUTOINCREMENT,",
		"                key TEXT UNIQUE,",
		"                value TEXT,",
		"                created_at TEXT",
		"            )",
		'            """)',
		"        conn.close()",
		"",
		"# --- small sqlite-backed key-value store ---",
		"class KVStore:",
		"    def __init__(self, db_path: str):",
		"        self.db_path = db_path",
		"        self._lock = threading.RLock()",
		"",
		"    def set(self, key: str, value: Any):",
		"        s = json.dumps(value, default=str)",
		"        with self._lock, sqlite3.connect(self.db_path) as conn:",
		"            conn.execute(",
		'                "INSERT INTO records(key, value, created_at) VALUES(?,?,?) ON CONFLICT(key) DO UPDATE SET value=excluded.value, created_at=excluded.created_at",',
		"                (key, s, datetime.utcnow().isoformat())",
		"            )",
		"",
		"    def get(self, key: str, /, default=None):",
		"        with self._lock, sqlite3.connect(self.db_path) as conn:",
		'            cur = conn.execute("SELECT value FROM records WHERE key = ?", (key,))',
		"            row = cur.fetchone()",
		"            if row:",
		"                return json.loads(row[0])",
		"        return default",
		"",
		"    def delete(self, key: str):",
		"        with self._lock, sqlite3.connect(self.db_path) as conn:",
		'            conn.execute("DELETE FROM records WHERE key = ?", (key,))',
		"",
		"    def keys(self) -> List[str]:",
		"        with self._lock, sqlite3.connect(self.db_path) as conn:",
		'            cur = conn.execute("SELECT key FROM records")',
		"            return [r[0] for r in cur.fetchall()]",
		"",
		"# --- file cache utility ---",
		"class FileCache:",
		"    def __init__(self, directory: str):",
		"        self.dir = Path(directory)",
		"        self.dir.mkdir(parents=True, exist_ok=True)",
		"",
		"    def path_for(self, key: str) -> Path:",
		'        safe = "".join(c if c.isalnum() or c in "._-" else "_" for c in key)',
		'        return self.dir / f"{safe}.json"',
		"",
		"    def write(self, key: str, obj: Any):",
		"        p = self.path_for(key)",
		'        with p.open("w", encoding="utf-8") as f:',
		"            json.dump(obj, f, default=str)",
		"",
		"    def read(self, key: str, default=None):",
		"        p = self.path_for(key)",
		"        if not p.exists():",
		"            return default",
		'        with p.open("r", encoding="utf-8") as f:',
		"            return json.load(f)",
		"",
		"    def clear(self):",
		'        for p in self.dir.glob("*.json"):',
		"            try:",
		"                p.unlink()",
		"            except Exception:",
		"                pass",
		"",
		"# --- background task runner with concurrency control ---",
		"class TaskRunner:",
		"    def __init__(self, max_workers: int = 4):",
		"        self.max_workers = max_workers",
		"        self._tasks = queue.Queue()",
		"        self._workers: List[threading.Thread] = []",
		"        self._stop = threading.Event()",
		"",
		"    def start(self):",
		"        for _ in range(self.max_workers):",
		"            t = threading.Thread(target=self._worker, daemon=True)",
		"            t.start()",
		"            self._workers.append(t)",
		"",
		"    def _worker(self):",
		"        while not self._stop.is_set():",
		"            try:",
		"                fn, args, kwargs = self._tasks.get(timeout=0.5)",
		"            except queue.Empty:",
		"                continue",
		"            try:",
		"                fn(*args, **kwargs)",
		"            except Exception:",
		"                traceback.print_exc()",
		"            finally:",
		"                self._tasks.task_done()",
		"",
		"    def submit(self, fn: Callable, *args, **kwargs):",
		"        self._tasks.put((fn, args, kwargs))",
		"",
		"    def shutdown(self, wait: bool = True):",
		"        self._stop.set()",
		"        if wait:",
		"            for w in self._workers:",
		"                w.join(timeout=1)",
		"",
		"# --- simple CSV processor with transform pipeline ---",
		"class CSVProcessor:",
		"    def __init__(self, filepath: str):",
		"        self.filepath = filepath",
		"",
		"    def stream_rows(self) -> Iterable[Dict[str, str]]:",
		"        with open(self.filepath, newline='', encoding='utf-8') as f:",
		"            reader = csv.DictReader(f)",
		"            for row in reader:",
		"                yield row",
		"",
		"    def filter_rows(self, predicate: Callable[[Dict[str, str]], bool]) -> List[Dict[str, str]]:",
		"        return [r for r in self.stream_rows() if predicate(r)]",
		"",
		"    def map_rows(self, mapper: Callable[[Dict[str, str]], Dict[str, Any]]) -> List[Dict[str, Any]]:",
		"        return [mapper(r) for r in self.stream_rows()]",
		"",
		"    def write_rows(self, rows: Iterable[Dict[str, Any]], outpath: str):",
		"        rows = list(rows)",
		"        if not rows:",
		"            return",
		"        keys = list(rows[0].keys())",
		"        with open(outpath, 'w', newline='', encoding='utf-8') as f:",
		"            writer = csv.DictWriter(f, fieldnames=keys)",
		"            writer.writeheader()",
		"            for r in rows:",
		"                writer.writerow(r)",
		"",
		"# --- a tiny HTTP JSON server that exposes KV store functionality ---",
		"class SimpleJSONHandler(http.server.SimpleHTTPRequestHandler):",
		"    def __init__(self, *args, kv: KVStore = None, **kwargs):",
		"        self.kv = kv",
		"        super().__init__(*args, **kwargs)",
		"",
		"    def _send_json(self, code: int, obj: Any):",
		"        body = json.dumps(obj, default=str).encode('utf-8')",
		"        self.send_response(code)",
		"        self.send_header('Content-Type', 'application/json; charset=utf-8')",
		"        self.send_header('Content-Length', str(len(body)))",
		"        self.end_headers()",
		"        self.wfile.write(body)",
		"",
		"    def do_GET(self):",
		'        if self.path.startswith("/kv/"):',
		'            key = self.path[len("/kv/"):]',
		"            val = self.kv.get(key, None)",
		"            if val is None:",
		'                self._send_json(404, {"error": "not found"})',
		"            else:",
		'                self._send_json(200, {"key": key, "value": val})',
		"            return",
		'        if self.path == "/keys":',
		'            self._send_json(200, {"keys": self.kv.keys()})',
		"            return",
		"        return super().do_GET()",
		"",
		"    def do_POST(self):",
		'        if self.path.startswith("/kv/"):',
		'            key = self.path[len("/kv/"):]',
		"            length = int(self.headers.get('Content-Length', 0))",
		'            data = self.rfile.read(length) if length else b"{}"',
		"            try:",
		"                payload = json.loads(data)",
		"            except Exception:",
		'                self._send_json(400, {"error": "invalid json"})',
		"                return",
		'            self.kv.set(key, payload.get("value"))',
		'            self._send_json(200, {"status": "ok", "key": key})',
		"            return",
		'        self._send_json(404, {"error": "unknown endpoint"})',
		"",
		"def run_http_server(port: int, kv: KVStore, stop_event: threading.Event):",
		"    handler_factory = lambda *args, **kwargs: SimpleJSONHandler(*args, kv=kv, **kwargs)",
		'    with socketserver.TCPServer(("", port), handler_factory) as httpd:',
		"        httpd.timeout = 0.5",
		"        while not stop_event.is_set():",
		"            httpd.handle_request()",
		"",
		"# --- synthetic data generator and a tiny prediction model ---",
		"class SyntheticGenerator:",
		"    def __init__(self, seed: Optional[int] = None):",
		"        self.rng = random.Random(seed)",
		"",
		"    def generate_point(self) -> Dict[str, float]:",
		"        x = self.rng.uniform(-10, 10)",
		"        y = 0.5 * x + 2.0 + self.rng.gauss(0, 1.0)",
		'        return {"x": x, "y": y}',
		"",
		"    def batch(self, n: int) -> List[Dict[str, float]]:",
		"        return [self.generate_point() for _ in range(n)]",
		"",
		"class SimpleLinearModel:",
		"    def __init__(self):",
		"        self.m = 0.0",
		"        self.b = 0.0",
		"        self.trained = False",
		"",
		"    def train(self, points: Iterable[Dict[str, float]], lr: float = 0.001, epochs: int = 1000):",
		'        xs = [p["x"] for p in points]',
		'        ys = [p["y"] for p in points]',
		"        n = len(xs)",
		"        if n == 0:",
		"            return",
		"        m, b = 0.0, sum(ys) / n",
		"        for _ in range(epochs):",
		"            pred = [m * x + b for x in xs]",
		"            dm = (-2 / n) * sum(x * (y - yp) for x, y, yp in zip(xs, ys, pred))",
		"            db = (-2 / n) * sum((y - yp) for y, yp in zip(ys, pred))",
		"            m -= lr * dm",
		"            b -= lr * db",
		"        self.m, self.b = m, b",
		"        self.trained = True",
		"",
		"    def predict(self, x: float) -> float:",
		"        return self.m * x + self.b",
		"",
		"# --- small scheduler for delayed tasks and periodic jobs ---",
		"class Scheduler:",
		"    def __init__(self):",
		"        self.jobs: List[Tuple[float, Callable, Tuple, Dict]] = []",
		"        self._lock = threading.RLock()",
		"        self._thread = threading.Thread(target=self._run, daemon=True)",
		"        self._stop = threading.Event()",
		"        self._thread.start()",
		"",
		"    def schedule_at(self, when: datetime, fn: Callable, *args, **kwargs):",
		"        ts = when.timestamp()",
		"        with self._lock:",
		"            self.jobs.append((ts, fn, args, kwargs))",
		"",
		"    def schedule_after(self, delay: float, fn: Callable, *args, **kwargs):",
		"        self.schedule_at(datetime.utcnow() + timedelta(seconds=delay), fn, *args, **kwargs)",
		"",
		"    def _run(self):",
		"        while not self._stop.is_set():",
		"            now = time.time()",
		"            to_run = []",
		"            with self._lock:",
		"                remaining = []",
		"                for job in self.jobs:",
		"                    if job[0] <= now:",
		"                        to_run.append(job)",
		"                    else:",
		"                        remaining.append(job)",
		"                self.jobs = remaining",
		"            for _, fn, args, kwargs in to_run:",
		"                try:",
		"                    threading.Thread(target=fn, args=args, kwargs=kwargs, daemon=True).start()",
		"                except Exception:",
		"                    traceback.print_exc()",
		"            time.sleep(0.5)",
		"",
		"    def stop(self):",
		"        self._stop.set()",
		"        self._thread.join(timeout=1)",
		"",
		"# --- utility exporters and importers ---",
		"def export_json(obj: Any, path: str):",
		"    with open(path, 'w', encoding='utf-8') as f:",
		"        json.dump(obj, f, default=str, indent=2)",
		"",
		"def import_json(path: str):",
		"    with open(path, 'r', encoding='utf-8') as f:",
		"        return json.load(f)",
		"",
		"# --- command-line interface wiring ---",
		"def cmd_generate(args: argparse.Namespace, cfg: Config, kv: KVStore, cache: FileCache):",
		"    gen = SyntheticGenerator(seed=args.seed)",
		"    batch = gen.batch(args.count)",
		'    cache.write("latest_batch", batch)',
		'    kv.set("last_generated", {"count": args.count, "time": datetime.utcnow().isoformat()})',
		"    print(f\"generated {len(batch)} points and cached to {cache.path_for('latest_batch')}\")",
		"",
		"def cmd_train(args: argparse.Namespace, cfg: Config, kv: KVStore, cache: FileCache):",
		'    data = cache.read("latest_batch", [])',
		"    if not data:",
		'        print("no cached data; generating a small dataset")',
		"        data = SyntheticGenerator(seed=42).batch(200)",
		"    model = SimpleLinearModel()",
		"    model.train(data, lr=args.lr, epochs=args.epochs)",
		'    kv.set("model", {"m": model.m, "b": model.b})',
		'    export_json({"m": model.m, "b": model.b}, "model.json")',
		'    print(f"trained model m={model.m:.4f} b={model.b:.4f} and exported to model.json")',
		"",
		"def cmd_predict(args: argparse.Namespace, cfg: Config, kv: KVStore, cache: FileCache):",
		'    mdata = kv.get("model")',
		"    if not mdata:",
		'        print("no model found; train first")',
		"        return",
		'    m, b = float(mdata["m"]), float(mdata["b"])',
		"    xs = args.xs or [0.0]",
		"    preds = [m * float(x) + b for x in xs]",
		"    for x, p in zip(xs, preds):",
		'        print(f"x={x} -> y={p}")',
		"",
		"def cmd_csv(args: argparse.Namespace, cfg: Config, kv: KVStore, cache: FileCache):",
		"    proc = CSVProcessor(args.input)",
		"    rows = proc.filter_rows(lambda r: all(r.values()))",
		'    mapped = proc.map_rows(lambda r: {**r, "score": sum(len(v) for v in r.values())})',
		'    out = args.output or ("processed_" + Path(args.input).name)',
		"    proc.write_rows(mapped, out)",
		'    print(f"wrote {len(mapped)} processed rows to {out}")',
		"",
		"def cmd_http(args: argparse.Namespace, cfg: Config, kv: KVStore, cache: FileCache):",
		"    stop_event = threading.Event()",
		"    t = threading.Thread(target=run_http_server, args=(cfg.http_port, kv, stop_event), daemon=True)",
		"    t.start()",
		'    print(f"http server running on port {cfg.http_port}; press Ctrl-C to stop")',
		"    try:",
		"        while True:",
		"            time.sleep(1)",
		"    except KeyboardInterrupt:",
		"        stop_event.set()",
		'        print("stopping server...")',
		"",
		"def cmd_cache_clear(args: argparse.Namespace, cfg: Config, kv: KVStore, cache: FileCache):",
		"    cache.clear()",
		'    print("cache cleared")',
		"",
		"def cmd_db_info(args: argparse.Namespace, cfg: Config, kv: KVStore, cache: FileCache):",
		'    print("db keys:", kv.keys())',
		"",
		"def build_parser() -> argparse.ArgumentParser:",
		'    p = argparse.ArgumentParser(prog="toolbox", description="collection of small utilities")',
		'    p.add_argument("--db", default="toolbox.db", help="path to sqlite db")',
		'    sub = p.add_subparsers(dest="cmd")',
		"",
		'    g = sub.add_parser("generate")',
		'    g.add_argument("--count", type=int, default=100, help="how many points to generate")',
		'    g.add_argument("--seed", type=int, default=None)',
		"    g.set_defaults(func=cmd_generate)",
		"",
		'    t = sub.add_parser("train")',
		'    t.add_argument("--epochs", type=int, default=500)',
		'    t.add_argument("--lr", type=float, default=0.001)',
		"    t.set_defaults(func=cmd_train)",
		"",
		'    pr = sub.add_parser("predict")',
		'    pr.add_argument("xs", nargs="*", type=float)',
		"    pr.set_defaults(func=cmd_predict)",
		"",
		'    c = sub.add_parser("csv")',
		'    c.add_argument("input", help="input csv file")',
		'    c.add_argument("--output", help="output csv path")',
		"    c.set_defaults(func=cmd_csv)",
		"",
		'    h = sub.add_parser("http")',
		"    h.set_defaults(func=cmd_http)",
		"",
		'    cc = sub.add_parser("cache-clear")',
		"    cc.set_defaults(func=cmd_cache_clear)",
		"",
		'    di = sub.add_parser("db-info")',
		"    di.set_defaults(func=cmd_db_info)",
		"",
		"    return p",
		"",
		"def main(argv: Optional[List[str]] = None):",
		"    parser = build_parser()",
		"    args = parser.parse_args(argv)",
		"    cfg = Config()",
		"    cfg.ensure()",
		"    kv = KVStore(cfg.db_path)",
		"    cache = FileCache(cfg.cache_dir)",
		"    if not args.cmd:",
		"        parser.print_help()",
		"        return",
		"    try:",
		"        args.func(args, cfg, kv, cache)",
		"    except Exception:",
		"        traceback.print_exc()",
		"",
		'if __name__ == "__main__":',
		"    main()",
	],
};

interface TypedLine {
	text: string;
	id: number;
	isComplete: boolean;
}

// CodeBG Component
export function CodeBG({ children }: { children: ReactNode }) {
	const [lines, setLines] = useState<TypedLine[]>([]);
	const [currentLine, setCurrentLine] = useState("");
	const [currentIndex, setCurrentIndex] = useState(0);
	const lineIdRef = useRef(0);
	const containerRef = useRef<HTMLDivElement>(null);
	const velocityX = useMotionValue(0);
	const velocityY = useMotionValue(0);
	const prevEvent = useRef(0);
	const languageRef = useRef<string[]>([]);
	const snippetIndexRef = useRef(0);

	useEffect(() => {
		// Pick random language on mount
		const languages = Object.keys(codeSnippets);
		const randomLang = languages[Math.floor(Math.random() * languages.length)];
		languageRef.current = codeSnippets[randomLang as keyof typeof codeSnippets];
	}, []);

	useEffect(() => {
		if (languageRef.current.length === 0) return;

		const snippet = languageRef.current[snippetIndexRef.current % languageRef.current.length];

		if (currentIndex < snippet.length) {
			const timeout = setTimeout(
				() => {
					setCurrentLine(snippet.slice(0, currentIndex + 1));
					setCurrentIndex(currentIndex + 1);
				},
				30 + Math.random() * 40
			);
			return () => clearTimeout(timeout);
		} else {
			// Line complete, submit it
			const timeout = setTimeout(() => {
				setLines((prev) => [...prev, { text: snippet, id: lineIdRef.current++, isComplete: true }]);
				setCurrentLine("");
				setCurrentIndex(0);
				snippetIndexRef.current++;

				// Keep only last 25 lines
				if (lines.length > 25) {
					setLines((prev) => prev.slice(-25));
				}
			}, 200);
			return () => clearTimeout(timeout);
		}
	}, [currentIndex, lines.length]);

	useEffect(() => {
		const handlePointerMove = (event: PointerEvent) => {
			const now = performance.now();
			const timeSinceLastEvent = (now - prevEvent.current) / 1000;
			prevEvent.current = now;
			velocityX.set(event.movementX / timeSinceLastEvent);
			velocityY.set(event.movementY / timeSinceLastEvent);
		};

		document.addEventListener("pointermove", handlePointerMove);
		return () => document.removeEventListener("pointermove", handlePointerMove);
	}, []);

	const handleCharHover = (e: React.MouseEvent<HTMLSpanElement>) => {
		const element = e.currentTarget;
		const speed = Math.sqrt(velocityX.get() * velocityX.get() + velocityY.get() * velocityY.get());
		const angle = Math.atan2(velocityY.get(), velocityX.get());
		const distance = speed * 0.1;

		animate(
			element,
			{
				x: Math.cos(angle) * distance,
				y: Math.sin(angle) * distance,
			},
			{ type: "spring", stiffness: 100, damping: 50 }
		);
	};

	return (
		<div className="relative w-full h-full">
			<div
				ref={containerRef}
				className="absolute inset-0 overflow-hidden pointer-events-auto"
				style={{
					fontFamily: '"Azeret Mono", "Courier New", monospace',
					fontSize: "13px",
					lineHeight: "21px",
					backgroundImage: "repeating-linear-gradient(transparent 0px, transparent 20px, rgba(255, 255, 255, 0.03) 20px, rgba(255, 255, 255, 0.03) 21px)",
				}}
			>
				<div className="p-6 pl-8">
					{lines.map((line) => (
						<div key={line.id} className="text-gray-400 font-mono" style={{ minHeight: "21px" }}>
							{line.text.split("").map((char, i) => (
								<span key={i} onMouseEnter={handleCharHover} className="inline-block will-change-transform" style={{ display: "inline-block" }}>
									{char === " " ? "\u00A0" : char}
								</span>
							))}
						</div>
					))}
					<div className="text-gray-500 font-mono" style={{ minHeight: "21px" }}>
						{currentLine}
						<span className="inline-block w-0.5 h-4 bg-blue-500 animate-pulse ml-px" />
					</div>
				</div>
			</div>

			<div className="relative z-10 pointer-events-none">{children}</div>
		</div>
	);
}

// TypeWriter component
function TypeWriter({ script }: { script: Array<{ text: string; endDelay?: number; backspace?: "character" | "word" | "all" }> }) {
	const [scriptIndex, setScriptIndex] = useState(0);
	const [displayText, setDisplayText] = useState("");
	const [isDeleting, setIsDeleting] = useState(false);
	const [charIndex, setCharIndex] = useState(0);

	const currentScript = script[scriptIndex];

	useEffect(() => {
		if (!currentScript) return;

		if (!isDeleting && charIndex < currentScript.text.length) {
			const timeout = setTimeout(
				() => {
					setDisplayText(currentScript.text.slice(0, charIndex + 1));
					setCharIndex(charIndex + 1);
				},
				50 + Math.random() * 50
			);
			return () => clearTimeout(timeout);
		} else if (!isDeleting && charIndex === currentScript.text.length) {
			const timeout = setTimeout(
				() => {
					setIsDeleting(true);
				},
				(currentScript.endDelay || 0.8) * 1000
			);
			return () => clearTimeout(timeout);
		} else if (isDeleting && charIndex > 0) {
			const timeout = setTimeout(() => {
				setDisplayText(currentScript.text.slice(0, charIndex - 1));
				setCharIndex(charIndex - 1);
			}, 30);
			return () => clearTimeout(timeout);
		} else if (isDeleting && charIndex === 0) {
			setIsDeleting(false);
			setScriptIndex((scriptIndex + 1) % script.length);
		}
	}, [charIndex, isDeleting, currentScript, scriptIndex, script]);

	return <>{displayText}</>;
}
